{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff04440-8080-4635-ac32-430ac6f7eff4",
   "metadata": {},
   "source": [
    "#### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af71c6bf-604a-4f0c-a18c-6f91bbcf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, \\\n",
    "    BatchNormalization, Flatten, LSTM\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45a7c3",
   "metadata": {},
   "source": [
    "#### PARAMETERS\n",
    "- Set the condition\n",
    "> * N_FEATURES: Number of Features\n",
    "> * CHECK_BLANKS: Check for blank data. If any blank data is found, the whole row of data will be deleted.\n",
    "> * CHECK_CLASS_IMBALANCE: Check for dataset class imbalance. The more balance the dataset, the less biases the model will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7460824",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 54>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m MODEL_DIR_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m MODEL_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier_del\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 54\u001b[0m DATASET_DIR_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), DATASET_DIR_NAME)\n\u001b[0;32m     55\u001b[0m SAMPLE_DATASET_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATASET_DIR_PATH, SAMPLE_DATASET_NAME)\n\u001b[0;32m     56\u001b[0m ACTUAL_DATASET_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATASET_DIR_PATH, ACTUAL_DATASET_NAME)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# # deep learning features # #\n",
    "##############################\n",
    "SEED = 1005 # random seed for reproducibility\n",
    "\n",
    "# should make this dynamic\n",
    "N_FEATURES = 37 #644 #322 #644 #37 #644 #37 #98 #190 #61 #37 #46\n",
    "# N_CLASSES=3\n",
    "TIMESTEPS = 1\n",
    "EPOCH=200\n",
    "BATCH_SIZE=10\n",
    "\n",
    "SPLIT_RATIO=0.2\n",
    "\n",
    "###############\n",
    "# # preview # #\n",
    "###############\n",
    "f = False\n",
    "t = True\n",
    "\n",
    "# checking dataset\n",
    "CHECK_BLANKS = True\n",
    "CHECK_CLASS_IMBALANCE = True\n",
    "\n",
    "# evaluate suitable kfold number and kfold model\n",
    "MIN_KFOLD = 2\n",
    "MAX_KFOLD = 11\n",
    "N_KFOLD = 5\n",
    "EVAL_KFOLD_NUM = False\n",
    "EVAL_KFOLD_MODEL = False\n",
    "PERFORM_KFOLD = True\n",
    "\n",
    "# model testing\n",
    "TEST_MODEL = False\n",
    "CON_MATRIX = False\n",
    "ROC_GRAPH = False\n",
    "\n",
    "###############\n",
    "# # dataset # #\n",
    "###############\n",
    "DATASET_DIR_NAME = \"dataset\"\n",
    "SAMPLE_DATASET_NAME = \"train\" + \".csv\"\n",
    "ACTUAL_DATASET_NAME = \"test\" + \".csv\"\n",
    "\n",
    "# SAMPLE_DATASET_NAME = \"train_m2m_tengraph\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"test_m2m_tengraph\" + \".csv\"\n",
    "\n",
    "# SAMPLE_DATASET_NAME = \"andy\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"andy\" + \".csv\"\n",
    "\n",
    "MODEL_DIR_NAME = \"model\"\n",
    "MODEL_NAME = \"classifier_del\" + \".h5\"\n",
    "\n",
    "RESULT_NAME = \"own_full_v4\" + \".csv\"\n",
    "\n",
    "DATASET_DIR_PATH = os.path.join(os.getcwd(), DATASET_DIR_NAME)\n",
    "SAMPLE_DATASET_PATH = os.path.join(DATASET_DIR_PATH, SAMPLE_DATASET_NAME)\n",
    "ACTUAL_DATASET_PATH = os.path.join(DATASET_DIR_PATH, ACTUAL_DATASET_NAME)\n",
    "\n",
    "MODEL_DIR_PATH = os.path.join(os.getcwd(), MODEL_DIR_NAME)\n",
    "MODEL_PATH = os.path.join(MODEL_DIR_PATH, MODEL_NAME)\n",
    "\n",
    "CLASSES_COL_NAME = \"Subject\"\n",
    "CLASSES_COL_NUM = 0\n",
    "FEATURES_COL_NUM = 3\n",
    "\n",
    "CLASS_LIST = ['andy', 'azfar', 'ch', 'cy', 'gerald', 'jc', 'jonah', 'qikai', 'ys', 'zen']\n",
    "\n",
    "#################\n",
    "# # sns theme # #\n",
    "#################\n",
    "# sns.set_theme(style=\"darkgrid\") # (dark background with white gridlines)\n",
    "sns.set_theme(style=\"whitegrid\") # (white background with grey gridlines)\n",
    "# sns.set_theme(style=\"dark\") # (dark background with no gridlines)\n",
    "# sns.set_theme(style=\"white\") # (white background with no gridlines)\n",
    "# sns.set_theme(style=\"ticks\") # (white background with axis ticks and no gridlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b4aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isdir(DATASET_DIR_PATH) is True:\n",
    "    print(f\"Dataset directory exists at: {DATASET_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(DATASET_DIR_PATH, 666)\n",
    "        print(f\"Dataset directory have been created at: {DATASET_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Dataset Directory not created\")\n",
    "        \n",
    "if os.path.isdir(MODEL_DIR_PATH) is True:\n",
    "    print(f\"Model directory exists at: {MODEL_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(MODEL_DIR_PATH, 666)\n",
    "        print(f\"Model directory have been created at: {MODEL_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Model Directory not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52cdd5",
   "metadata": {},
   "source": [
    "#### CREATE MODEL\n",
    "- Create base model\n",
    "- Wrap it with KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f633b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base model\n",
    "# def create_base_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(units=1024, return_sequences=True,\n",
    "#              input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(LSTM(units=512, return_sequences=True))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(units=256, return_sequences=True))\n",
    "#     model.add(Dropout(0.2))\n",
    "# #     model.add(LSTM(units=128, return_sequences=True))\n",
    "# #     model.add(Dropout(0.2))\n",
    "# #     model.add(LSTM(units=128, return_sequences=True))\n",
    "# #     model.add(Dropout(0.2))\n",
    "# #     model.add(LSTM(units=128, return_sequences=True))\n",
    "# #     model.add(BatchNormalization())\n",
    "# #     model.add(LSTM(units=64, return_sequences=True))\n",
    "# #     model.add(Dropout(0.2))\n",
    "# #     model.add(LSTM(units=32, return_sequences=True))\n",
    "# #     model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "#     # softmax for multi-class classification\n",
    "#     model.add(Flatten())\n",
    "#     print(n_classes)\n",
    "#     model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "#                 metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "#create base model\n",
    "def create_base_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, return_sequences=True,\n",
    "             input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "    model.add(Dense(128, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dense(64, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=32, return_sequences=True))\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # softmax for multi-class classification\n",
    "    model.add(Flatten())\n",
    "    print(n_classes)\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# wrap model in KerasClassifier\n",
    "def create_model():\n",
    "    model = KerasClassifier(build_fn=create_base_model, epochs=EPOCH, \n",
    "                            batch_size=BATCH_SIZE)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2280ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into features X and target (classes) Y\n",
    "def prepare_dataset(df):\n",
    "    X = df.values[:,FEATURES_COL_NUM:].astype(float)\n",
    "    Y = df.values[:,CLASSES_COL_NUM].astype(str)\n",
    "\n",
    "    # convert target Y to labelbinarizer Y for model\n",
    "    # fit_transform is not used to reuse lb\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    lb = LabelBinarizer().fit(Y)\n",
    "    Y = lb.transform(Y)\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # # get all the encoded class # #\n",
    "    #################################\n",
    "    print(\"LabelBinarizer is able to decipher: \")\n",
    "    print(lb.classes_)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ###########################\n",
    "    # # print X and Y shape # #\n",
    "    ###########################\n",
    "    print(f\"X | Features | Dataset Shape: {X.shape}\")\n",
    "    print(f\"Y | Classes  | Dataset Shape: {Y.shape}\")\n",
    "\n",
    "    return X, Y, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2cd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_shape_dataset(X, Y, SPLIT_RATIO, TIMESTEPS, SEED):\n",
    "\n",
    "    ##############################################################\n",
    "    # # split dataset into train and test set of 0.8/0.2 ratio # #\n",
    "    ##############################################################\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=SPLIT_RATIO, random_state=SEED)\n",
    "\n",
    "    ############################\n",
    "    # # reshaping of dataset # #\n",
    "    ############################\n",
    "\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], TIMESTEPS, X_train.shape[1]))\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], TIMESTEPS, X_test.shape[1]))\n",
    "\n",
    "    # retrieve number of classes\n",
    "    n_classes = y_train.shape[1]\n",
    "\n",
    "    print(f\"X train shape: {X_train.shape}\")\n",
    "    print(f\"Y train shape: {y_train.shape}\")\n",
    "    print(f\"X test shape: {X_test.shape}\")\n",
    "    print(f\"Y test shape: {y_test.shape}\")\n",
    "    print(f\"Number of Classes: {n_classes}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, n_classes\n",
    "\n",
    "def reshape_dataset(X, TIMESTEPS):\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    X = np.reshape(X, (X.shape[0], TIMESTEPS, X.shape[1]))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244ab5e",
   "metadata": {},
   "source": [
    "#### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8126e914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>D|0</th>\n",
       "      <th>I|0+1</th>\n",
       "      <th>PF|0+1</th>\n",
       "      <th>RF|0+1</th>\n",
       "      <th>D|1</th>\n",
       "      <th>I|1+2</th>\n",
       "      <th>PF|1+2</th>\n",
       "      <th>...</th>\n",
       "      <th>RF|6+7</th>\n",
       "      <th>D|7</th>\n",
       "      <th>I|7+8</th>\n",
       "      <th>PF|7+8</th>\n",
       "      <th>RF|7+8</th>\n",
       "      <th>D|8</th>\n",
       "      <th>I|8+9</th>\n",
       "      <th>PF|8+9</th>\n",
       "      <th>RF|8+9</th>\n",
       "      <th>D|9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andy</td>\n",
       "      <td>3</td>\n",
       "      <td>mad wabble</td>\n",
       "      <td>0.155289</td>\n",
       "      <td>0.234703</td>\n",
       "      <td>0.091736</td>\n",
       "      <td>0.079413</td>\n",
       "      <td>0.142967</td>\n",
       "      <td>0.238084</td>\n",
       "      <td>0.072560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165704</td>\n",
       "      <td>0.119107</td>\n",
       "      <td>0.171939</td>\n",
       "      <td>0.040368</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>0.131571</td>\n",
       "      <td>0.188983</td>\n",
       "      <td>0.075754</td>\n",
       "      <td>0.057412</td>\n",
       "      <td>0.113230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andy</td>\n",
       "      <td>3</td>\n",
       "      <td>bad reread</td>\n",
       "      <td>0.116150</td>\n",
       "      <td>0.285436</td>\n",
       "      <td>0.085726</td>\n",
       "      <td>0.169286</td>\n",
       "      <td>0.199709</td>\n",
       "      <td>0.248351</td>\n",
       "      <td>0.127091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076081</td>\n",
       "      <td>0.160108</td>\n",
       "      <td>0.271197</td>\n",
       "      <td>0.069895</td>\n",
       "      <td>0.111089</td>\n",
       "      <td>0.201302</td>\n",
       "      <td>0.291623</td>\n",
       "      <td>0.135957</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.155666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andy</td>\n",
       "      <td>3</td>\n",
       "      <td>ink sienna</td>\n",
       "      <td>0.118185</td>\n",
       "      <td>0.273710</td>\n",
       "      <td>0.114184</td>\n",
       "      <td>0.155524</td>\n",
       "      <td>0.159526</td>\n",
       "      <td>0.248386</td>\n",
       "      <td>0.106931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196050</td>\n",
       "      <td>0.086095</td>\n",
       "      <td>0.257720</td>\n",
       "      <td>0.139502</td>\n",
       "      <td>0.171624</td>\n",
       "      <td>0.118217</td>\n",
       "      <td>0.253027</td>\n",
       "      <td>0.124216</td>\n",
       "      <td>0.134809</td>\n",
       "      <td>0.128811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andy</td>\n",
       "      <td>3</td>\n",
       "      <td>ion doxies</td>\n",
       "      <td>0.082255</td>\n",
       "      <td>0.330661</td>\n",
       "      <td>0.189420</td>\n",
       "      <td>0.248406</td>\n",
       "      <td>0.141242</td>\n",
       "      <td>0.283131</td>\n",
       "      <td>0.142228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124682</td>\n",
       "      <td>0.141366</td>\n",
       "      <td>0.203498</td>\n",
       "      <td>0.086235</td>\n",
       "      <td>0.062132</td>\n",
       "      <td>0.117263</td>\n",
       "      <td>0.199387</td>\n",
       "      <td>0.054129</td>\n",
       "      <td>0.082124</td>\n",
       "      <td>0.145257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andy</td>\n",
       "      <td>3</td>\n",
       "      <td>hey plains</td>\n",
       "      <td>0.106697</td>\n",
       "      <td>0.214285</td>\n",
       "      <td>0.117489</td>\n",
       "      <td>0.107588</td>\n",
       "      <td>0.096796</td>\n",
       "      <td>0.225085</td>\n",
       "      <td>0.090808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109095</td>\n",
       "      <td>0.125539</td>\n",
       "      <td>0.198049</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>0.072510</td>\n",
       "      <td>0.152043</td>\n",
       "      <td>0.221190</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>0.069147</td>\n",
       "      <td>0.138667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  Class    Sequence       D|0     I|0+1    PF|0+1    RF|0+1  \\\n",
       "0    andy      3  mad wabble  0.155289  0.234703  0.091736  0.079413   \n",
       "1    andy      3  bad reread  0.116150  0.285436  0.085726  0.169286   \n",
       "2    andy      3  ink sienna  0.118185  0.273710  0.114184  0.155524   \n",
       "3    andy      3  ion doxies  0.082255  0.330661  0.189420  0.248406   \n",
       "4    andy      3  hey plains  0.106697  0.214285  0.117489  0.107588   \n",
       "\n",
       "        D|1     I|1+2    PF|1+2  ...    RF|6+7       D|7     I|7+8    PF|7+8  \\\n",
       "0  0.142967  0.238084  0.072560  ...  0.165704  0.119107  0.171939  0.040368   \n",
       "1  0.199709  0.248351  0.127091  ...  0.076081  0.160108  0.271197  0.069895   \n",
       "2  0.159526  0.248386  0.106931  ...  0.196050  0.086095  0.257720  0.139502   \n",
       "3  0.141242  0.283131  0.142228  ...  0.124682  0.141366  0.203498  0.086235   \n",
       "4  0.096796  0.225085  0.090808  ...  0.109095  0.125539  0.198049  0.046005   \n",
       "\n",
       "     RF|7+8       D|8     I|8+9    PF|8+9    RF|8+9       D|9  \n",
       "0  0.052832  0.131571  0.188983  0.075754  0.057412  0.113230  \n",
       "1  0.111089  0.201302  0.291623  0.135957  0.090321  0.155666  \n",
       "2  0.171624  0.118217  0.253027  0.124216  0.134809  0.128811  \n",
       "3  0.062132  0.117263  0.199387  0.054129  0.082124  0.145257  \n",
       "4  0.072510  0.152043  0.221190  0.082523  0.069147  0.138667  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "\n",
    "\n",
    "\n",
    "# df.drop(df[df['Subject']=='andy'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='azfar'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='ch'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='cy'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='gerald'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='jc'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='jonah'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='qikai'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='ys'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='zen'].index, inplace=True)\n",
    "\n",
    "# CLASS_LIST = ['andy', 'azfar', 'ch', 'cy', 'gerald', 'jc', 'jonah', 'qikai', 'ys', 'zen']\n",
    "# CLASS_LIST = ['ch', 'cy', 'jc', 'ys', 'zen']\n",
    "# CLASS_LIST = ['andy', 'azfar', 'ch', 'cy']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13daa1c",
   "metadata": {},
   "source": [
    "#### CHECK DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d2ac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for blanks...\n",
      "No blank value has been found.\n",
      "Checking for class imbalance...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################\n",
    "# # check for blanks # #\n",
    "########################\n",
    "if CHECK_BLANKS is True:\n",
    "    # checking for blanks\n",
    "    print(\"Checking for blanks...\")\n",
    "    if df.isnull().values.any() is True:\n",
    "        df = df.dropna(axis=0, how=\"any\")\n",
    "        print(\"Blank rows has been dropped.\")\n",
    "    else:\n",
    "        print(\"No blank value has been found.\")\n",
    "        \n",
    "#################################\n",
    "# # check for class imbalance # #\n",
    "#################################\n",
    "if CHECK_CLASS_IMBALANCE is True:\n",
    "    print(\"Checking for class imbalance...\")\n",
    "    sns.countplot(x=CLASSES_COL_NAME, data=df).set_title(\"Class Imbalance\")\n",
    "#     df.loc[(df!=0).any(axis=1)]\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|0\", data=df)\n",
    "\n",
    "    \n",
    "#     sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|3\", hue=\"D|3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|4\", hue=\"D|4\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|5\", hue=\"D|5\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|6\", hue=\"D|6\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|7\", hue=\"D|7\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|8\", hue=\"D|8\", data=df, legend=False)\n",
    "\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"I|1+2\", hue=\"I|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"PF|1+2\", hue=\"PF|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"RF|1+2\", hue=\"RF|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"DT|1+2\", hue=\"DT|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|9\", hue=\"D|9\", data=df, legend=False)\n",
    "\n",
    "\n",
    "#     sns.catplot(x=\"Subject\", y=\"TT|1+3\", hue=\"TT|1+3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"QT|1+4\", hue=\"QT|1+4\", data=df, legend=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9b784",
   "metadata": {},
   "source": [
    "#### PREPARE DATASET\n",
    "- Split data based on X / Features and Y / Classes\n",
    "- Binarize Y into binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8119c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelBinarizer is able to decipher: \n",
      "['andy' 'azfar' 'ch' 'cy' 'gerald' 'jc' 'jonah' 'qikai' 'ys' 'zen']\n",
      "\n",
      "\n",
      "X | Features | Dataset Shape: (920, 37)\n",
      "Y | Classes  | Dataset Shape: (920, 10)\n"
     ]
    }
   ],
   "source": [
    "X, Y, lb = prepare_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fbc1a",
   "metadata": {},
   "source": [
    "#### SPLIT DATASET\n",
    "- Split dataset into train set and test set 0.8 / 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "474f4106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float64\n",
      "float32\n",
      "X train shape: (736, 1, 37)\n",
      "Y train shape: (736, 10)\n",
      "X test shape: (184, 1, 37)\n",
      "Y test shape: (184, 10)\n",
      "Number of Classes: 10\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# # split dataset into train and test set of 0.8/0.2 ratio # #\n",
    "##############################################################\n",
    "X_train, X_test, y_train, y_test, n_classes = split_shape_dataset(X, Y, SPLIT_RATIO, TIMESTEPS, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3cb08",
   "metadata": {},
   "source": [
    "#### PERFORM VALIDATION (w KFold Validation)\n",
    "- Evaluate best KFold Validation\n",
    "- Generate loss and accuracy graph\n",
    "- Perform KFold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54349ee1",
   "metadata": {},
   "source": [
    "##### Evaluate suitable folds for kfold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5ec946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_KFOLD_NUM is not True\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# # evaluate suitable kfold value for model # #\n",
    "###############################################\n",
    "def evaluate_kfold(X_train, y_train, SEED, MIN_KFOLD, MAX_KFOLD):\n",
    "    \n",
    "    # evaluate the model    \n",
    "    folds = range(MIN_KFOLD, MAX_KFOLD)\n",
    "    means, mins, maxs = list(), list(), list()\n",
    "    \n",
    "    # evaluate each k value\n",
    "    for k in folds:\n",
    "        # define the test condition\n",
    "        kfold = KFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        # evaluate k value\n",
    "        model = create_model()\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=kfold, n_jobs=-1)\n",
    "        \n",
    "        k_mean = np.mean(scores)\n",
    "        k_min = scores.min()\n",
    "        k_max = scores.max()\n",
    "        \n",
    "        # report performance\n",
    "        print(f\"No. of Folds: {k} | Accuracy: {k_mean*100:.3f} | Min: {k_min*100:.3f} | Max: {k_max*100:.3f}\")\n",
    "        \n",
    "        # store mean accuracy and min and max relative to the mean\n",
    "        means.append(k_mean)\n",
    "        mins.append(k_mean - k_min)\n",
    "        maxs.append(k_max - k_mean)\n",
    "        \n",
    "    # line plot of k mean values with min/max error bars\n",
    "    clear_output(wait=True)\n",
    "    pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "    \n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    \n",
    "if EVAL_KFOLD_NUM is True:\n",
    "    evaluate_kfold(X_train, y_train, SEED, MIN_KFOLD, MAX_KFOLD)\n",
    "else:\n",
    "    print(\"EVAL_KFOLD_NUM is not True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d290e",
   "metadata": {},
   "source": [
    "##### Generate kfold validation accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b6b796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_KFOLD_MODEL is not true\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# # evaluate kfold model for accuracy and loss # #\n",
    "##################################################\n",
    "def evaluate_kfold_model(X_train, y_train, SEED):\n",
    "    scores, histories = list(), list()\n",
    "    # create model\n",
    "    model = create_model()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X_train):\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = X_train[train_ix], y_train[train_ix], X_train[test_ix], y_train[test_ix]\n",
    "        # fit model\n",
    "        history = model.fit(trainX, trainY, epochs=100, batch_size=50, validation_data=(testX, testY), verbose=0)\n",
    "        \n",
    "        # evaluate model\n",
    "        y_pred = model.predict(testX)\n",
    "        y_pred = to_categorical(y_pred)\n",
    "\n",
    "        # evaluate predictions\n",
    "        acc = accuracy_score(testY, y_pred)\n",
    "        print(\"Testing accuracy: %.3f%%\" % (acc*100))\n",
    "\n",
    "        # stores scores and histories\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        f1 = plt.figure(1)\n",
    "        plt.title('Categorical Cross-Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'], color='blue')\n",
    "        plt.plot(histories[i].history['val_loss'], color='orange')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "        # plot accuracy\n",
    "        f2 = plt.figure(2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['accuracy'], color='blue')\n",
    "        plt.plot(histories[i].history['val_accuracy'], color='orange')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "    # print summary\n",
    "    print(f\"Accuracy | Mean: {np.mean(scores)*100:.3f} | Std: {np.std(scores)*100:.3f} | Length/no.: {len(scores)}\")\n",
    "    # box and whisker plots of results\n",
    "    f3 = plt.figure(3)\n",
    "    plt.title('Box and Whisker Plot of Accuracy Scores')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('model')\n",
    "    plt.boxplot(scores)\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    \n",
    "if EVAL_KFOLD_MODEL is True:\n",
    "    evaluate_kfold_model(X_train, y_train, SEED)\n",
    "else:\n",
    "    print(\"EVAL_KFOLD_MODEL is not true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7133b",
   "metadata": {},
   "source": [
    "##### Perform Actual KFold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4411e204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 5s 7ms/step - loss: 2.3897 - accuracy: 0.0833\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.3624 - accuracy: 0.0782\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3600 - accuracy: 0.1020\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.3501 - accuracy: 0.0782\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.3197 - accuracy: 0.1190\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.3319 - accuracy: 0.0884\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.2800 - accuracy: 0.1378\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.2285 - accuracy: 0.1769\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.1810 - accuracy: 0.1701\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.1274 - accuracy: 0.2041\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 2.1074 - accuracy: 0.1684\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.0765 - accuracy: 0.1871\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.0826 - accuracy: 0.1871\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0658 - accuracy: 0.1735\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0284 - accuracy: 0.1752\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0291 - accuracy: 0.1922\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.0174 - accuracy: 0.2194\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9829 - accuracy: 0.2245\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9550 - accuracy: 0.2228\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.9805 - accuracy: 0.2194\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9363 - accuracy: 0.2262\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9161 - accuracy: 0.2313\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9582 - accuracy: 0.1837\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9196 - accuracy: 0.2313\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9019 - accuracy: 0.2517\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8848 - accuracy: 0.2619\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.8962 - accuracy: 0.2534\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.8336 - accuracy: 0.2687\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.8201 - accuracy: 0.2823\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.7816 - accuracy: 0.3129\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.8365 - accuracy: 0.2823\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.8168 - accuracy: 0.3044\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.7400 - accuracy: 0.3095\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.7106 - accuracy: 0.3486\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.6881 - accuracy: 0.3588\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.6788 - accuracy: 0.3554\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.6254 - accuracy: 0.3878\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.6633 - accuracy: 0.3639\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.6304 - accuracy: 0.3724\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5951 - accuracy: 0.3707\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5969 - accuracy: 0.3741\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5194 - accuracy: 0.4014\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5584 - accuracy: 0.3963\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5945 - accuracy: 0.3810\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5221 - accuracy: 0.4235\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5922 - accuracy: 0.3895\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5044 - accuracy: 0.4014\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5330 - accuracy: 0.4031\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4835 - accuracy: 0.4235\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5174 - accuracy: 0.4286\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4813 - accuracy: 0.4575\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4463 - accuracy: 0.4643\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4502 - accuracy: 0.4422\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4650 - accuracy: 0.4677\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5098 - accuracy: 0.4218\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4413 - accuracy: 0.4490\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4418 - accuracy: 0.4677\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4380 - accuracy: 0.4388\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4834 - accuracy: 0.4405\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4328 - accuracy: 0.4337\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4518 - accuracy: 0.4354\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4236 - accuracy: 0.4558\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4358 - accuracy: 0.4643\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4650 - accuracy: 0.4354\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4276 - accuracy: 0.4524\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3765 - accuracy: 0.4388\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4006 - accuracy: 0.4728\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4078 - accuracy: 0.4473\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3883 - accuracy: 0.4915\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4392 - accuracy: 0.4422\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4274 - accuracy: 0.4558\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3911 - accuracy: 0.4541\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4119 - accuracy: 0.4762\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3523 - accuracy: 0.4898\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3919 - accuracy: 0.4541\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 1s 8ms/step - loss: 1.3719 - accuracy: 0.4830\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3462 - accuracy: 0.4830\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3457 - accuracy: 0.4966\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4153 - accuracy: 0.4439\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3826 - accuracy: 0.4813\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3761 - accuracy: 0.4677\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3312 - accuracy: 0.5034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3473 - accuracy: 0.4949\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3828 - accuracy: 0.4830\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3387 - accuracy: 0.4983\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3566 - accuracy: 0.4813\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3653 - accuracy: 0.4898\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3609 - accuracy: 0.4898\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3389 - accuracy: 0.4881\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3379 - accuracy: 0.5136\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3365 - accuracy: 0.4762\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3567 - accuracy: 0.4762\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3049 - accuracy: 0.4864\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3017 - accuracy: 0.5187\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3026 - accuracy: 0.4915\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3062 - accuracy: 0.5051\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3224 - accuracy: 0.5051\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3365 - accuracy: 0.4881\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3071 - accuracy: 0.5119\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3114 - accuracy: 0.4847\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2753 - accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3435 - accuracy: 0.4915\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.3231 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2422 - accuracy: 0.5255\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2663 - accuracy: 0.5272\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2632 - accuracy: 0.5476\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2537 - accuracy: 0.5323\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2856 - accuracy: 0.5272\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2679 - accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.3376 - accuracy: 0.4898\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2599 - accuracy: 0.5170\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2421 - accuracy: 0.5136\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.2905 - accuracy: 0.5187\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.2891 - accuracy: 0.5017\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.2756 - accuracy: 0.5340\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.2393 - accuracy: 0.5272\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.1720 - accuracy: 0.5204\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.2308 - accuracy: 0.5119\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.2307 - accuracy: 0.5051\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.3276 - accuracy: 0.5306\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.2367 - accuracy: 0.5425\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.1985 - accuracy: 0.5340\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.1997 - accuracy: 0.5493\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.2799 - accuracy: 0.5204\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2310 - accuracy: 0.5544\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.2653 - accuracy: 0.4813\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2910 - accuracy: 0.5153\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2159 - accuracy: 0.5306\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2635 - accuracy: 0.5017\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2272 - accuracy: 0.5306\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2372 - accuracy: 0.5340\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1440 - accuracy: 0.5595\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2405 - accuracy: 0.5204\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2097 - accuracy: 0.5374\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1886 - accuracy: 0.5493\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1773 - accuracy: 0.5680\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2269 - accuracy: 0.5374\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1885 - accuracy: 0.5629\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2320 - accuracy: 0.5493\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1893 - accuracy: 0.5561\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2101 - accuracy: 0.5459\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2089 - accuracy: 0.5680\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1519 - accuracy: 0.5612\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1974 - accuracy: 0.5493\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1977 - accuracy: 0.5340\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2225 - accuracy: 0.5629\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1902 - accuracy: 0.5561\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2163 - accuracy: 0.5663\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2264 - accuracy: 0.5442\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1775 - accuracy: 0.5119\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2162 - accuracy: 0.5527\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1197 - accuracy: 0.6020\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1584 - accuracy: 0.5510\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1997 - accuracy: 0.5731\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1839 - accuracy: 0.5748\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2070 - accuracy: 0.5306\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2042 - accuracy: 0.5289\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1606 - accuracy: 0.5765\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1355 - accuracy: 0.5850\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1478 - accuracy: 0.5493\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2291 - accuracy: 0.5323\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2118 - accuracy: 0.5561\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1446 - accuracy: 0.5646\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1450 - accuracy: 0.5748\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1911 - accuracy: 0.5663\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1449 - accuracy: 0.5544\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1788 - accuracy: 0.5425\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1525 - accuracy: 0.5714\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1855 - accuracy: 0.5578\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1726 - accuracy: 0.5697\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1655 - accuracy: 0.5612\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1029 - accuracy: 0.5884\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1247 - accuracy: 0.5833\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1420 - accuracy: 0.5765\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1383 - accuracy: 0.5765\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0967 - accuracy: 0.5867\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1324 - accuracy: 0.5833\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1379 - accuracy: 0.5510\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1830 - accuracy: 0.5731\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1183 - accuracy: 0.5799\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0791 - accuracy: 0.5833\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1112 - accuracy: 0.5629\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0997 - accuracy: 0.5884\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1567 - accuracy: 0.5493\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1088 - accuracy: 0.5935\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1446 - accuracy: 0.5765\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1093 - accuracy: 0.5935\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1391 - accuracy: 0.6037\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1341 - accuracy: 0.5816\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1149 - accuracy: 0.5833\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1628 - accuracy: 0.5527\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0998 - accuracy: 0.5765\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1253 - accuracy: 0.5901\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1280 - accuracy: 0.5782\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1127 - accuracy: 0.5969\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0871 - accuracy: 0.6105\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1127 - accuracy: 0.5748\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1175 - accuracy: 0.5867\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1476 - accuracy: 0.5612\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1218 - accuracy: 0.5901\n",
      "15/15 [==============================] - 1s 3ms/step - loss: 1.1766 - accuracy: 0.5946\n",
      "10\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 5s 6ms/step - loss: 2.4838 - accuracy: 0.0832\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3781 - accuracy: 0.0900\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3472 - accuracy: 0.0917\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.3355 - accuracy: 0.1070\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3424 - accuracy: 0.1222\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.2940 - accuracy: 0.1256\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.2277 - accuracy: 0.1952\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.2314 - accuracy: 0.1426\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.1446 - accuracy: 0.1800\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.1246 - accuracy: 0.1630\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.1082 - accuracy: 0.1477\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0941 - accuracy: 0.1783\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0626 - accuracy: 0.1817\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0678 - accuracy: 0.1749\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9813 - accuracy: 0.2173\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9980 - accuracy: 0.2003\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9392 - accuracy: 0.2309\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9425 - accuracy: 0.2377\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9529 - accuracy: 0.2360\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9305 - accuracy: 0.2360\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.8672 - accuracy: 0.2852\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8075 - accuracy: 0.3039\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7782 - accuracy: 0.3362\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7918 - accuracy: 0.2683\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7768 - accuracy: 0.3328\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7906 - accuracy: 0.3158\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7320 - accuracy: 0.3226\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6776 - accuracy: 0.3447\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7206 - accuracy: 0.3226\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.6838 - accuracy: 0.3345\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6604 - accuracy: 0.3362\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6949 - accuracy: 0.3124\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6813 - accuracy: 0.3413\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6074 - accuracy: 0.3769\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6480 - accuracy: 0.3752\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.6432 - accuracy: 0.3413\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5948 - accuracy: 0.3718\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6019 - accuracy: 0.3565\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5557 - accuracy: 0.3667\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6097 - accuracy: 0.3769\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5827 - accuracy: 0.3939\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5582 - accuracy: 0.4007\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5461 - accuracy: 0.3871\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5491 - accuracy: 0.3786\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5622 - accuracy: 0.4143\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5710 - accuracy: 0.3786\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5481 - accuracy: 0.4211\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5439 - accuracy: 0.4075\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5221 - accuracy: 0.4058\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5086 - accuracy: 0.3871\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4904 - accuracy: 0.4295\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5060 - accuracy: 0.4363\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5345 - accuracy: 0.4261\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.4547 - accuracy: 0.4346\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4820 - accuracy: 0.4244\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.4238 - accuracy: 0.4363\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4444 - accuracy: 0.4516\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5207 - accuracy: 0.4244\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4487 - accuracy: 0.4550\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5116 - accuracy: 0.4126\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4962 - accuracy: 0.4194\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4211 - accuracy: 0.4584\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4482 - accuracy: 0.4261\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4214 - accuracy: 0.4567\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4714 - accuracy: 0.4312\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4323 - accuracy: 0.4652\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4240 - accuracy: 0.4550\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4618 - accuracy: 0.4448\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4188 - accuracy: 0.4669\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4068 - accuracy: 0.4635\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3978 - accuracy: 0.4720\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3993 - accuracy: 0.4652\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3931 - accuracy: 0.4754\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4186 - accuracy: 0.4618\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4013 - accuracy: 0.4652\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4557 - accuracy: 0.4499\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4163 - accuracy: 0.4465\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4065 - accuracy: 0.4465\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3643 - accuracy: 0.4771\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3477 - accuracy: 0.4822\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3440 - accuracy: 0.4856\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3677 - accuracy: 0.4652\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3685 - accuracy: 0.4941\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3488 - accuracy: 0.4890\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3793 - accuracy: 0.4856\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3482 - accuracy: 0.5059\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4023 - accuracy: 0.4567\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4189 - accuracy: 0.4448\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3804 - accuracy: 0.4924\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3286 - accuracy: 0.4754\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3269 - accuracy: 0.5076\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3255 - accuracy: 0.4652\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3289 - accuracy: 0.5229\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2865 - accuracy: 0.5008\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3185 - accuracy: 0.4924\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3388 - accuracy: 0.5008\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2836 - accuracy: 0.5331\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3163 - accuracy: 0.4839\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3370 - accuracy: 0.4839\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3132 - accuracy: 0.5110\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2972 - accuracy: 0.5042\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3369 - accuracy: 0.4924\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2978 - accuracy: 0.5127\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2767 - accuracy: 0.5178\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2386 - accuracy: 0.5042\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3827 - accuracy: 0.5212\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2503 - accuracy: 0.5280\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2537 - accuracy: 0.5246\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2953 - accuracy: 0.4958\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2956 - accuracy: 0.4856\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3043 - accuracy: 0.4788\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2589 - accuracy: 0.5195\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2466 - accuracy: 0.5229\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2801 - accuracy: 0.4907\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2549 - accuracy: 0.5195\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2186 - accuracy: 0.5178\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2887 - accuracy: 0.4754\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2349 - accuracy: 0.5229\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2470 - accuracy: 0.5127\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2401 - accuracy: 0.5314\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2606 - accuracy: 0.5212\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2850 - accuracy: 0.4805\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2409 - accuracy: 0.5127\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2612 - accuracy: 0.5110\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2790 - accuracy: 0.5110\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2443 - accuracy: 0.5331\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2404 - accuracy: 0.5059\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2946 - accuracy: 0.5093\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2480 - accuracy: 0.5348\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2280 - accuracy: 0.5416\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1950 - accuracy: 0.5331\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2486 - accuracy: 0.5467\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.2318 - accuracy: 0.5297\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2199 - accuracy: 0.5093\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2667 - accuracy: 0.5008\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2519 - accuracy: 0.5433\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2203 - accuracy: 0.5127\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1976 - accuracy: 0.5382\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1830 - accuracy: 0.5280\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2194 - accuracy: 0.5331\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2278 - accuracy: 0.5178\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2397 - accuracy: 0.5263\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1862 - accuracy: 0.5348\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1739 - accuracy: 0.5467\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2232 - accuracy: 0.5382\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2383 - accuracy: 0.5161\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2000 - accuracy: 0.5161\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2633 - accuracy: 0.5263\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2269 - accuracy: 0.5314\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2560 - accuracy: 0.5144\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1829 - accuracy: 0.5586\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2504 - accuracy: 0.5314\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2068 - accuracy: 0.5382\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1721 - accuracy: 0.5586\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1863 - accuracy: 0.5365\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2224 - accuracy: 0.5433\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1684 - accuracy: 0.5484\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1641 - accuracy: 0.5212\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1811 - accuracy: 0.5331\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1919 - accuracy: 0.5263\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1965 - accuracy: 0.5212\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2078 - accuracy: 0.5450\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1543 - accuracy: 0.5569\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1781 - accuracy: 0.5484\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1782 - accuracy: 0.5535\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1461 - accuracy: 0.5518\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2060 - accuracy: 0.5416\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2042 - accuracy: 0.5297\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1246 - accuracy: 0.5552\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1726 - accuracy: 0.5552\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2153 - accuracy: 0.5637\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1765 - accuracy: 0.5552\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1706 - accuracy: 0.5348\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1514 - accuracy: 0.5297\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1720 - accuracy: 0.5433\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1481 - accuracy: 0.5705\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1245 - accuracy: 0.5484\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1167 - accuracy: 0.5823\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1324 - accuracy: 0.5484\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1922 - accuracy: 0.5586\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1367 - accuracy: 0.5569\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1060 - accuracy: 0.5484\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1114 - accuracy: 0.5671\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1776 - accuracy: 0.5467\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1701 - accuracy: 0.5535\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1715 - accuracy: 0.5552\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1586 - accuracy: 0.5569\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1296 - accuracy: 0.5637\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1257 - accuracy: 0.5806\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1520 - accuracy: 0.5416\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1042 - accuracy: 0.5857\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1711 - accuracy: 0.5586\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1043 - accuracy: 0.5772\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1855 - accuracy: 0.5399\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1560 - accuracy: 0.5467\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1461 - accuracy: 0.5705\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0975 - accuracy: 0.5569\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1239 - accuracy: 0.5722\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1116 - accuracy: 0.5603\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1833 - accuracy: 0.5552\n",
      "15/15 [==============================] - 2s 4ms/step - loss: 1.2045 - accuracy: 0.5374\n",
      "10\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 9s 6ms/step - loss: 2.4219 - accuracy: 0.0883\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.3469 - accuracy: 0.1053\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3333 - accuracy: 0.1087\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3109 - accuracy: 0.1256\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3197 - accuracy: 0.1171\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.2680 - accuracy: 0.1511\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.2121 - accuracy: 0.1630\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.1294 - accuracy: 0.2003\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.1269 - accuracy: 0.1817\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0804 - accuracy: 0.2071\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0494 - accuracy: 0.1851\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0584 - accuracy: 0.1868\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0478 - accuracy: 0.1834\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0385 - accuracy: 0.2020\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9765 - accuracy: 0.2411\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9976 - accuracy: 0.2088\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9812 - accuracy: 0.2224\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9537 - accuracy: 0.2343\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9398 - accuracy: 0.2581\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8784 - accuracy: 0.2869\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8722 - accuracy: 0.2716\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8338 - accuracy: 0.3243\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.7730 - accuracy: 0.3141\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7289 - accuracy: 0.3616\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7128 - accuracy: 0.3667\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7624 - accuracy: 0.3480\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.7059 - accuracy: 0.3362\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7038 - accuracy: 0.3633\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6576 - accuracy: 0.3599\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6298 - accuracy: 0.3684\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6572 - accuracy: 0.3701\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6100 - accuracy: 0.3820\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5822 - accuracy: 0.4024\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6204 - accuracy: 0.3718\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5840 - accuracy: 0.3803\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6178 - accuracy: 0.3990\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5756 - accuracy: 0.3939\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5943 - accuracy: 0.3752\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5125 - accuracy: 0.4312\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5412 - accuracy: 0.4075\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5781 - accuracy: 0.3888\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5271 - accuracy: 0.4075\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5671 - accuracy: 0.4278\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5440 - accuracy: 0.4143\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5012 - accuracy: 0.4126\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5137 - accuracy: 0.4278\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5413 - accuracy: 0.4058\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5442 - accuracy: 0.4024\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5236 - accuracy: 0.4092\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4774 - accuracy: 0.4143\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5264 - accuracy: 0.4126\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5146 - accuracy: 0.4244\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5154 - accuracy: 0.4109\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5118 - accuracy: 0.4397\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4981 - accuracy: 0.4109\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4510 - accuracy: 0.4448\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4467 - accuracy: 0.4567\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4242 - accuracy: 0.4720\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4758 - accuracy: 0.4465\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4138 - accuracy: 0.4822\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4334 - accuracy: 0.4160\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4349 - accuracy: 0.4584\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4283 - accuracy: 0.4465\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4570 - accuracy: 0.4533\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3727 - accuracy: 0.5042\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4136 - accuracy: 0.4533\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4210 - accuracy: 0.4533\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4335 - accuracy: 0.4261\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4397 - accuracy: 0.4635\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.4075 - accuracy: 0.4499\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4402 - accuracy: 0.4431\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.4031 - accuracy: 0.4618\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3732 - accuracy: 0.4839\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4163 - accuracy: 0.4618\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4189 - accuracy: 0.4618\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3988 - accuracy: 0.4720\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3687 - accuracy: 0.4703\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3537 - accuracy: 0.4975\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4247 - accuracy: 0.4805\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3908 - accuracy: 0.4907\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4235 - accuracy: 0.4703\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3985 - accuracy: 0.4788\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3961 - accuracy: 0.4720\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4240 - accuracy: 0.4805\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4529 - accuracy: 0.4397\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3412 - accuracy: 0.5025\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4113 - accuracy: 0.4601\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3258 - accuracy: 0.4907\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3780 - accuracy: 0.4567\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3365 - accuracy: 0.4856\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3723 - accuracy: 0.4890\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3836 - accuracy: 0.4584\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3439 - accuracy: 0.4924\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3218 - accuracy: 0.4975\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3511 - accuracy: 0.4839\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3326 - accuracy: 0.4822\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4058 - accuracy: 0.4788\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3214 - accuracy: 0.5144\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3316 - accuracy: 0.4822\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3091 - accuracy: 0.5093\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2889 - accuracy: 0.5076\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3189 - accuracy: 0.4992\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3623 - accuracy: 0.4686\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3516 - accuracy: 0.4703\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3247 - accuracy: 0.4805\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2697 - accuracy: 0.5042\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3529 - accuracy: 0.4873\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3120 - accuracy: 0.5212\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3276 - accuracy: 0.4873\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3154 - accuracy: 0.4873\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3489 - accuracy: 0.4873\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2750 - accuracy: 0.5161\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3210 - accuracy: 0.4924\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3208 - accuracy: 0.5008\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2570 - accuracy: 0.5178\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2420 - accuracy: 0.5127\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2729 - accuracy: 0.5042\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2952 - accuracy: 0.4788\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2714 - accuracy: 0.5178\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2630 - accuracy: 0.5195\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2761 - accuracy: 0.4958\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2772 - accuracy: 0.5076\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3110 - accuracy: 0.4941\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2717 - accuracy: 0.4890\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2229 - accuracy: 0.5365\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2723 - accuracy: 0.5212\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2806 - accuracy: 0.5348\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3106 - accuracy: 0.5144\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2736 - accuracy: 0.5229\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2203 - accuracy: 0.5110\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2439 - accuracy: 0.5297\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2369 - accuracy: 0.5127\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2510 - accuracy: 0.4890\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2726 - accuracy: 0.5246\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2273 - accuracy: 0.5263\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2444 - accuracy: 0.4992\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2850 - accuracy: 0.5246\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2162 - accuracy: 0.5212\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2374 - accuracy: 0.5552\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.5297\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1561 - accuracy: 0.5569\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1778 - accuracy: 0.5552\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2314 - accuracy: 0.5229\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2266 - accuracy: 0.5365\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2514 - accuracy: 0.5297\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2167 - accuracy: 0.5620\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2092 - accuracy: 0.5297\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1657 - accuracy: 0.5739\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2244 - accuracy: 0.5297\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1989 - accuracy: 0.5467\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1994 - accuracy: 0.5365\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2087 - accuracy: 0.5110\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2113 - accuracy: 0.5501\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2602 - accuracy: 0.5144\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2134 - accuracy: 0.5195\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2142 - accuracy: 0.5467\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1503 - accuracy: 0.5739\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5382\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2451 - accuracy: 0.5348\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.5416\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2649 - accuracy: 0.5297\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2556 - accuracy: 0.5195\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2002 - accuracy: 0.5688\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1723 - accuracy: 0.5467\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1733 - accuracy: 0.5416\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2330 - accuracy: 0.5229\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2263 - accuracy: 0.5178\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2602 - accuracy: 0.5229\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1900 - accuracy: 0.5552\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1454 - accuracy: 0.5365\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1570 - accuracy: 0.5518\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1855 - accuracy: 0.5501\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1291 - accuracy: 0.5501\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1861 - accuracy: 0.5484\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1803 - accuracy: 0.5348\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1436 - accuracy: 0.5586\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1661 - accuracy: 0.5331\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1699 - accuracy: 0.5671\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1910 - accuracy: 0.5654\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1514 - accuracy: 0.5654\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1194 - accuracy: 0.5671\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1437 - accuracy: 0.5739\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1118 - accuracy: 0.5586\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1482 - accuracy: 0.5603\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1806 - accuracy: 0.5331\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1306 - accuracy: 0.5671\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1892 - accuracy: 0.5348\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1423 - accuracy: 0.5535\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1391 - accuracy: 0.5569\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1629 - accuracy: 0.5484\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1344 - accuracy: 0.5705\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1435 - accuracy: 0.5552\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0933 - accuracy: 0.5806\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1196 - accuracy: 0.5569\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1892 - accuracy: 0.5484\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1589 - accuracy: 0.5603\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1204 - accuracy: 0.5722\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1075 - accuracy: 0.5942\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1603 - accuracy: 0.5552\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1522 - accuracy: 0.5637\n",
      "15/15 [==============================] - 1s 3ms/step - loss: 1.3377 - accuracy: 0.4762\n",
      "10\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 5s 6ms/step - loss: 2.4332 - accuracy: 0.0917\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.3729 - accuracy: 0.1121\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3612 - accuracy: 0.0985\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.3184 - accuracy: 0.1171\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.2908 - accuracy: 0.1188\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.2085 - accuracy: 0.1698\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.1516 - accuracy: 0.1698\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.1105 - accuracy: 0.1698\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.0850 - accuracy: 0.1732\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.0806 - accuracy: 0.1868\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0182 - accuracy: 0.1868\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0263 - accuracy: 0.2020\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9757 - accuracy: 0.2275\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9430 - accuracy: 0.2071\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.9743 - accuracy: 0.2037\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9234 - accuracy: 0.2139\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.9452 - accuracy: 0.2207\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.9022 - accuracy: 0.2207\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8998 - accuracy: 0.2224\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8407 - accuracy: 0.2733\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8376 - accuracy: 0.2869\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.8191 - accuracy: 0.2971\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.8384 - accuracy: 0.2750\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7761 - accuracy: 0.3141\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7247 - accuracy: 0.3447\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.7332 - accuracy: 0.3311\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.7512 - accuracy: 0.3413\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.6616 - accuracy: 0.3633\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.6460 - accuracy: 0.3463\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6062 - accuracy: 0.3786\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6165 - accuracy: 0.3956\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5709 - accuracy: 0.3820\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5747 - accuracy: 0.3752\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5524 - accuracy: 0.3888\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6026 - accuracy: 0.3871\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5135 - accuracy: 0.4126\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.5682 - accuracy: 0.4228\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4950 - accuracy: 0.4346\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5543 - accuracy: 0.4092\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5446 - accuracy: 0.3905\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4612 - accuracy: 0.4448\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5238 - accuracy: 0.4007\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5026 - accuracy: 0.4363\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5415 - accuracy: 0.4024\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4841 - accuracy: 0.4092\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4328 - accuracy: 0.4516\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4899 - accuracy: 0.4397\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4538 - accuracy: 0.4363\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4858 - accuracy: 0.4380\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4689 - accuracy: 0.4533\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4679 - accuracy: 0.4244\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4603 - accuracy: 0.4499\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4076 - accuracy: 0.4482\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4162 - accuracy: 0.4669\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4271 - accuracy: 0.4414\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4593 - accuracy: 0.4550\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4436 - accuracy: 0.4465\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3953 - accuracy: 0.4839\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4124 - accuracy: 0.4788\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3713 - accuracy: 0.4873\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3704 - accuracy: 0.4873\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4536 - accuracy: 0.4414\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3494 - accuracy: 0.4992\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3961 - accuracy: 0.4652\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3842 - accuracy: 0.4703\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3660 - accuracy: 0.4448\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3981 - accuracy: 0.4567\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3588 - accuracy: 0.4771\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3361 - accuracy: 0.4703\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3804 - accuracy: 0.4601\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4077 - accuracy: 0.4873\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4415 - accuracy: 0.4499\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3503 - accuracy: 0.4873\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3105 - accuracy: 0.5161\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3642 - accuracy: 0.4754\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3242 - accuracy: 0.5008\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3668 - accuracy: 0.4788\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3246 - accuracy: 0.4975\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3461 - accuracy: 0.4941\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2897 - accuracy: 0.4788\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3327 - accuracy: 0.4924\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3343 - accuracy: 0.4992\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3059 - accuracy: 0.5042\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2849 - accuracy: 0.5110\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3248 - accuracy: 0.4635\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3305 - accuracy: 0.5076\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3118 - accuracy: 0.5110\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2564 - accuracy: 0.5059\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2951 - accuracy: 0.5212\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3637 - accuracy: 0.4567\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2898 - accuracy: 0.5093\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2406 - accuracy: 0.5212\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3057 - accuracy: 0.4788\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2809 - accuracy: 0.4941\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2923 - accuracy: 0.4924\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2645 - accuracy: 0.4992\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2294 - accuracy: 0.5042\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2689 - accuracy: 0.5144\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2920 - accuracy: 0.4958\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2742 - accuracy: 0.5229\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.3158 - accuracy: 0.4822\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2738 - accuracy: 0.5059\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.2884 - accuracy: 0.5008\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2962 - accuracy: 0.5161\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.2556 - accuracy: 0.5059\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2850 - accuracy: 0.4958\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2342 - accuracy: 0.5314\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.2495 - accuracy: 0.4890\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2442 - accuracy: 0.5127\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2245 - accuracy: 0.5008\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2711 - accuracy: 0.5229\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2422 - accuracy: 0.5229\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2388 - accuracy: 0.5263\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2805 - accuracy: 0.4924\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2598 - accuracy: 0.4975\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2810 - accuracy: 0.5229\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.2050 - accuracy: 0.5501\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1991 - accuracy: 0.5110\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2466 - accuracy: 0.5093\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1917 - accuracy: 0.5348\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2060 - accuracy: 0.5688\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1997 - accuracy: 0.5144\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2183 - accuracy: 0.5076\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2316 - accuracy: 0.5263\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2361 - accuracy: 0.5042\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2388 - accuracy: 0.5178\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2439 - accuracy: 0.5093\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2387 - accuracy: 0.4992\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2077 - accuracy: 0.5433\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2298 - accuracy: 0.5382\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1750 - accuracy: 0.5178\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2243 - accuracy: 0.5144\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1619 - accuracy: 0.5450\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1597 - accuracy: 0.5365\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2058 - accuracy: 0.5382\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1888 - accuracy: 0.5433\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2415 - accuracy: 0.5263\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2393 - accuracy: 0.5263\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1866 - accuracy: 0.5331\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1845 - accuracy: 0.5705\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1616 - accuracy: 0.5433\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1302 - accuracy: 0.5586\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2105 - accuracy: 0.5348\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1998 - accuracy: 0.5280\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1946 - accuracy: 0.5263\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1422 - accuracy: 0.5756\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1830 - accuracy: 0.5450\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1912 - accuracy: 0.5229\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1398 - accuracy: 0.5484\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2238 - accuracy: 0.5314\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1915 - accuracy: 0.5331\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.1286 - accuracy: 0.5722\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2123 - accuracy: 0.5416\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1433 - accuracy: 0.5535\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2094 - accuracy: 0.5280\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2002 - accuracy: 0.5195\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1576 - accuracy: 0.5518\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1799 - accuracy: 0.5586\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1400 - accuracy: 0.5722\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1658 - accuracy: 0.5467\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1438 - accuracy: 0.5518\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1595 - accuracy: 0.5654\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1237 - accuracy: 0.5705\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1233 - accuracy: 0.5365\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2657 - accuracy: 0.5144\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1584 - accuracy: 0.5467\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2030 - accuracy: 0.5501\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1343 - accuracy: 0.5569\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1372 - accuracy: 0.5671\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1634 - accuracy: 0.5433\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1963 - accuracy: 0.5365\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1286 - accuracy: 0.5722\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1738 - accuracy: 0.5620\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1311 - accuracy: 0.5603\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1731 - accuracy: 0.5484\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2036 - accuracy: 0.5314\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1112 - accuracy: 0.5433\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0855 - accuracy: 0.6078\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1124 - accuracy: 0.5756\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1409 - accuracy: 0.5433\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1337 - accuracy: 0.5501\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1014 - accuracy: 0.5908\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1290 - accuracy: 0.5705\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1311 - accuracy: 0.5467\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1759 - accuracy: 0.5552\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1773 - accuracy: 0.5586\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0801 - accuracy: 0.5722\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1219 - accuracy: 0.5603\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1351 - accuracy: 0.5501\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0866 - accuracy: 0.5772\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1623 - accuracy: 0.5705\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1895 - accuracy: 0.5806\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1147 - accuracy: 0.5705\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1484 - accuracy: 0.5603\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0834 - accuracy: 0.5586\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0541 - accuracy: 0.6061\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1310 - accuracy: 0.5789\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0975 - accuracy: 0.5891\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1130 - accuracy: 0.5772\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0919 - accuracy: 0.5993\n",
      "15/15 [==============================] - 1s 2ms/step - loss: 1.4070 - accuracy: 0.4762\n",
      "10\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 5s 6ms/step - loss: 2.4640 - accuracy: 0.0849\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3497 - accuracy: 0.1036\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3605 - accuracy: 0.0917\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.3481 - accuracy: 0.0849\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 2.3367 - accuracy: 0.0934\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.3354 - accuracy: 0.1070\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.3564 - accuracy: 0.0866\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 2.3188 - accuracy: 0.1154\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 8ms/step - loss: 2.2727 - accuracy: 0.1358\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.2424 - accuracy: 0.1596\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 2.1631 - accuracy: 0.1800\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 2.1015 - accuracy: 0.2088\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 2.0587 - accuracy: 0.2156\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 2.0036 - accuracy: 0.2292\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.9503 - accuracy: 0.2784\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.9002 - accuracy: 0.2818\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.8795 - accuracy: 0.3090\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.8065 - accuracy: 0.3056\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.7793 - accuracy: 0.3158\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.7603 - accuracy: 0.3362\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.7465 - accuracy: 0.3463\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.6816 - accuracy: 0.3616\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6950 - accuracy: 0.3548\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6724 - accuracy: 0.3599\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6342 - accuracy: 0.3939\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6679 - accuracy: 0.3718\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6678 - accuracy: 0.3497\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6335 - accuracy: 0.3888\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5794 - accuracy: 0.4058\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6597 - accuracy: 0.3480\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.5806 - accuracy: 0.3871\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6013 - accuracy: 0.3939\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.6065 - accuracy: 0.4024\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5911 - accuracy: 0.3956\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5299 - accuracy: 0.4160\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5720 - accuracy: 0.3956\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.5525 - accuracy: 0.4160\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5375 - accuracy: 0.4007\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5701 - accuracy: 0.4092\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5319 - accuracy: 0.4075\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5217 - accuracy: 0.4278\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4869 - accuracy: 0.4278\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4917 - accuracy: 0.4261\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4949 - accuracy: 0.4261\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4546 - accuracy: 0.4465\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5330 - accuracy: 0.4024\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.4907 - accuracy: 0.4584\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4638 - accuracy: 0.4397\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4898 - accuracy: 0.4211\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4688 - accuracy: 0.4499\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4535 - accuracy: 0.4550\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.5078 - accuracy: 0.4363\n",
      "Epoch 53/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4826 - accuracy: 0.4397\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.4874 - accuracy: 0.4414\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4710 - accuracy: 0.4448\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4731 - accuracy: 0.4431\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4538 - accuracy: 0.4448\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.4426 - accuracy: 0.4380\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4730 - accuracy: 0.4312\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4429 - accuracy: 0.4431\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4540 - accuracy: 0.4516\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4282 - accuracy: 0.4567\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4512 - accuracy: 0.4516\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3786 - accuracy: 0.4652\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3968 - accuracy: 0.4516\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4039 - accuracy: 0.4788\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3898 - accuracy: 0.4822\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4247 - accuracy: 0.4567\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4006 - accuracy: 0.4856\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4191 - accuracy: 0.4703\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4098 - accuracy: 0.4567\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3918 - accuracy: 0.4788\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3879 - accuracy: 0.4737\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.4289 - accuracy: 0.4550\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3479 - accuracy: 0.4975\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3575 - accuracy: 0.4907\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3332 - accuracy: 0.4924\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3509 - accuracy: 0.4754\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3732 - accuracy: 0.4788\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3377 - accuracy: 0.4754\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3330 - accuracy: 0.4958\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.4291 - accuracy: 0.4465\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3546 - accuracy: 0.5059\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3151 - accuracy: 0.4958\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3906 - accuracy: 0.4550\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3329 - accuracy: 0.5008\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3409 - accuracy: 0.5008\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2937 - accuracy: 0.5229\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2910 - accuracy: 0.5076\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3132 - accuracy: 0.4839\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3752 - accuracy: 0.4652\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3446 - accuracy: 0.4771\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3182 - accuracy: 0.5008\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3526 - accuracy: 0.4839\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3272 - accuracy: 0.4992\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2987 - accuracy: 0.4822\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2989 - accuracy: 0.4975\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3061 - accuracy: 0.5178\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3173 - accuracy: 0.5042\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2845 - accuracy: 0.5076\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3138 - accuracy: 0.5025\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3046 - accuracy: 0.4941\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3131 - accuracy: 0.5042\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.3060 - accuracy: 0.4822\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.3117 - accuracy: 0.5076\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.3248 - accuracy: 0.5042\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3206 - accuracy: 0.4754\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3439 - accuracy: 0.5076\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2758 - accuracy: 0.5008\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2438 - accuracy: 0.5110\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2601 - accuracy: 0.5195\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2560 - accuracy: 0.5076\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2414 - accuracy: 0.5161\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2522 - accuracy: 0.5025\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2843 - accuracy: 0.5076\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2452 - accuracy: 0.5144\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2383 - accuracy: 0.5178\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2348 - accuracy: 0.5246\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2166 - accuracy: 0.5484\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2639 - accuracy: 0.5178\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2672 - accuracy: 0.5144\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2373 - accuracy: 0.5280\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2389 - accuracy: 0.5178\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2297 - accuracy: 0.5331\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2574 - accuracy: 0.5110\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2299 - accuracy: 0.5246\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.5246\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.2606 - accuracy: 0.5280\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3032 - accuracy: 0.4975\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2295 - accuracy: 0.5280\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3066 - accuracy: 0.4941\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2195 - accuracy: 0.5246\n",
      "Epoch 133/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1977 - accuracy: 0.5178\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2440 - accuracy: 0.5229\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.2391 - accuracy: 0.5161\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.2220 - accuracy: 0.5195\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2141 - accuracy: 0.5348\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2605 - accuracy: 0.4975\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2101 - accuracy: 0.5518\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2453 - accuracy: 0.5246\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2602 - accuracy: 0.5365\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1783 - accuracy: 0.5365\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2441 - accuracy: 0.5263\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2053 - accuracy: 0.5586\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1678 - accuracy: 0.5586\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2397 - accuracy: 0.5229\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1864 - accuracy: 0.5178\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1855 - accuracy: 0.5008\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2146 - accuracy: 0.5535\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.2047 - accuracy: 0.5161\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2140 - accuracy: 0.5535\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1799 - accuracy: 0.5501\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1588 - accuracy: 0.5280\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2625 - accuracy: 0.5280\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1628 - accuracy: 0.5314\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1601 - accuracy: 0.5127\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2124 - accuracy: 0.5399\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1794 - accuracy: 0.5314\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1870 - accuracy: 0.5246\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1484 - accuracy: 0.5450\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1570 - accuracy: 0.5637\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2157 - accuracy: 0.5161\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1809 - accuracy: 0.5450\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1499 - accuracy: 0.5416\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1716 - accuracy: 0.5348\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1447 - accuracy: 0.5569\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1236 - accuracy: 0.5620\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1934 - accuracy: 0.5229\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1669 - accuracy: 0.5331\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1058 - accuracy: 0.5874\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1159 - accuracy: 0.5756\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1110 - accuracy: 0.5501\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1790 - accuracy: 0.5552\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1594 - accuracy: 0.5501\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1493 - accuracy: 0.5467\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1134 - accuracy: 0.5654\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1360 - accuracy: 0.5535\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1414 - accuracy: 0.5501\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1409 - accuracy: 0.5365\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1483 - accuracy: 0.5535\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1458 - accuracy: 0.5331\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.1278 - accuracy: 0.5586\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1855 - accuracy: 0.5297\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.1297 - accuracy: 0.5450\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0731 - accuracy: 0.5637\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1947 - accuracy: 0.5484\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1790 - accuracy: 0.5620\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1274 - accuracy: 0.5722\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0803 - accuracy: 0.5925\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1056 - accuracy: 0.5586\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1760 - accuracy: 0.5739\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1249 - accuracy: 0.5348\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 1.1911 - accuracy: 0.5382\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 1.1580 - accuracy: 0.5535\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.1045 - accuracy: 0.5671\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.1242 - accuracy: 0.5772\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 1.1134 - accuracy: 0.5501\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.2000 - accuracy: 0.5552\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.0844 - accuracy: 0.5942\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.1097 - accuracy: 0.5789\n",
      "15/15 [==============================] - 3s 3ms/step - loss: 1.1492 - accuracy: 0.5918\n"
     ]
    }
   ],
   "source": [
    "if PERFORM_KFOLD is True:\n",
    "    # create model\n",
    "    model = create_model()\n",
    "    kfold = KFold(n_splits=N_KFOLD, shuffle=True, random_state=SEED)\n",
    "    valid_score = cross_val_score(model, X_train, y_train, \n",
    "                          cv=kfold, error_score=\"raise\", verbose=0)\n",
    "else:\n",
    "    print(\"PERFORM_KFOLD is not true.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474856b9",
   "metadata": {},
   "source": [
    "##### Get Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0179a8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy of 53.52% (with standard deviation of 5.24%)\n"
     ]
    }
   ],
   "source": [
    "if PERFORM_KFOLD is True:\n",
    "    print(\"Validation Accuracy of %.2f%% (with standard deviation of %.2f%%)\" % \n",
    "      (valid_score.mean()*100, valid_score.std()*100))\n",
    "else:\n",
    "    print(\"PERFORM_KFOLD is not true.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18643ec",
   "metadata": {},
   "source": [
    "#### FIT MODEL FOR TESTING\n",
    "- Fit the Model\n",
    "- View Accuracy and Loss Graph\n",
    "- View Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f2f15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# # fit the model # #\n",
    "#####################\n",
    "\n",
    "if TEST_MODEL is True:\n",
    "    model = create_model()\n",
    "    es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
    "                       verbose=1)\n",
    "    history = model.fit(X_train, y_train, callbacks=es, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c058a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True:\n",
    "    ##########################\n",
    "    # # get model accuracy # #\n",
    "    ##########################\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    ######################\n",
    "    # # get model loss # #\n",
    "    ######################\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedbc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True:\n",
    "    ##########################\n",
    "    # # view model summary # #\n",
    "    ##########################\n",
    "    model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a64780",
   "metadata": {},
   "source": [
    "#### MODEL TESTING\n",
    "- Get Model Accuracy on the Test Dataset\n",
    "- Generate Confusion Matrix\n",
    "- Generate ROC Curves\n",
    "- Save the Model if Appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda705c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True:\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "\n",
    "    # evaluate predictions\n",
    "    acc = accuracy_score(lb.inverse_transform(y_test), lb.inverse_transform(y_pred))\n",
    "    print(\"Testing accuracy: %.3f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db889b",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6b6068e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and CON_MATRIX is True:\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(lb.inverse_transform(y_test), lb.inverse_transform(y_pred))\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in np.unique(lb.inverse_transform(y_test))],\n",
    "                         columns = [i for i in np.unique(lb.inverse_transform(y_test))])\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=True, cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9a1f8",
   "metadata": {},
   "source": [
    "##### ROC Curve (Individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f77dae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and ROC_GRAPH is True: # compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=\"darkorange\",\n",
    "            lw=lw,\n",
    "            label=\"ROC curve (area = %0.2f)\" % roc_auc[i],\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "        plt.xlim([-0.005, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve (\" + str(lb.classes_[i]) + \")\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53449bd8",
   "metadata": {},
   "source": [
    "##### ROC Curve (Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "717b1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and ROC_GRAPH is True:\n",
    "    # compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], thresholds = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # first aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    # plt.figure()\n",
    "    # plt.plot(\n",
    "    #     fpr[\"micro\"],\n",
    "    #     tpr[\"micro\"],\n",
    "    #     label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    #     color=\"deeppink\",\n",
    "    #     linestyle=\":\",\n",
    "    #     linewidth=4,\n",
    "    # )\n",
    "\n",
    "    # plt.plot(\n",
    "    #     fpr[\"macro\"],\n",
    "    #     tpr[\"macro\"],\n",
    "    #     label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    #     color=\"navy\",\n",
    "    #     linestyle=\":\",\n",
    "    #     linewidth=4,\n",
    "    # )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"lightgreen\", \"purple\"])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=color,\n",
    "            lw=lw,\n",
    "            label=\"ROC curve of class {0} (area = {1:0.2f})\".format(lb.classes_[i], roc_auc[i]),\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "    plt.xlim([-0.005, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve (Multiclass)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd4e12",
   "metadata": {},
   "source": [
    "##### ROC Curve (Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf917af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and ROC_GRAPH is True:\n",
    "    fpr, tpr, threshold = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "\n",
    "    # calculate equal-error-rate\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='AUC = {:.3f}, EER = {:.3f}'.format(auc(fpr, tpr), eer))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('Average ROC Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b17bde",
   "metadata": {},
   "source": [
    "#### FIT AND SAVE MODEL\n",
    "- Fitting of model\n",
    "- Get Accuracy and Loss of Mdoel\n",
    "- Saving MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5703966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelBinarizer is able to decipher: \n",
      "['andy' 'azfar' 'ch' 'cy' 'gerald' 'jc' 'jonah' 'qikai' 'ys' 'zen']\n",
      "\n",
      "\n",
      "X | Features | Dataset Shape: (920, 37)\n",
      "Y | Classes  | Dataset Shape: (920, 10)\n",
      "10\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 5s 5ms/step - loss: 2.4328 - accuracy: 0.1022\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.3608 - accuracy: 0.0804\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.3358 - accuracy: 0.1065\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.3098 - accuracy: 0.1196\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.2583 - accuracy: 0.1543\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.1563 - accuracy: 0.1978\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.0935 - accuracy: 0.1728\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.0552 - accuracy: 0.1902\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.0058 - accuracy: 0.2196\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2.0025 - accuracy: 0.2076\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.9387 - accuracy: 0.2370\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.9045 - accuracy: 0.2609\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.8571 - accuracy: 0.2761\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.7840 - accuracy: 0.3033\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.7160 - accuracy: 0.3402\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.6959 - accuracy: 0.3554\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.6774 - accuracy: 0.3609\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.6547 - accuracy: 0.3641\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.6564 - accuracy: 0.3478\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.6269 - accuracy: 0.3598\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.5906 - accuracy: 0.3967\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.5930 - accuracy: 0.3717\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.5928 - accuracy: 0.3620\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.5698 - accuracy: 0.3935\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.5636 - accuracy: 0.3978\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.5601 - accuracy: 0.4065\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.5400 - accuracy: 0.3957\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.5223 - accuracy: 0.3880\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.4848 - accuracy: 0.4380\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.4981 - accuracy: 0.4163\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.4764 - accuracy: 0.4261\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 1.4848 - accuracy: 0.4250\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4808 - accuracy: 0.4304\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4802 - accuracy: 0.4370\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.4554 - accuracy: 0.4261\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4265 - accuracy: 0.4707\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4989 - accuracy: 0.4228\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4468 - accuracy: 0.4478\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4164 - accuracy: 0.4500\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4453 - accuracy: 0.4380\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4474 - accuracy: 0.4413\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4174 - accuracy: 0.4674\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3808 - accuracy: 0.4685\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3848 - accuracy: 0.4533\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3873 - accuracy: 0.4522\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4156 - accuracy: 0.4446\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.4043 - accuracy: 0.4826\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3637 - accuracy: 0.4609\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3756 - accuracy: 0.4674\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3482 - accuracy: 0.4739\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3940 - accuracy: 0.4685\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3451 - accuracy: 0.4717\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3551 - accuracy: 0.4620\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3567 - accuracy: 0.4913\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3408 - accuracy: 0.4902\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3393 - accuracy: 0.4793\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3533 - accuracy: 0.4870\n",
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3068 - accuracy: 0.5098\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3327 - accuracy: 0.4913\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3917 - accuracy: 0.4620\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3198 - accuracy: 0.4793\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3604 - accuracy: 0.4707\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2912 - accuracy: 0.5141\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3388 - accuracy: 0.4793\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3072 - accuracy: 0.4902\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3228 - accuracy: 0.5109\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3117 - accuracy: 0.4946\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3497 - accuracy: 0.4783\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2993 - accuracy: 0.4880\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.3482 - accuracy: 0.4902\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 1.3291 - accuracy: 0.4761\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2837 - accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3134 - accuracy: 0.4913\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2774 - accuracy: 0.5130\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3246 - accuracy: 0.4880\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2936 - accuracy: 0.4957\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2559 - accuracy: 0.5098\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 1.3165 - accuracy: 0.5141\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2786 - accuracy: 0.5152\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3129 - accuracy: 0.4924\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2981 - accuracy: 0.4848\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2908 - accuracy: 0.5130\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.3245 - accuracy: 0.4913\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2753 - accuracy: 0.5087\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2741 - accuracy: 0.5141\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2789 - accuracy: 0.5043\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2620 - accuracy: 0.5098\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2620 - accuracy: 0.5076\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2796 - accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2851 - accuracy: 0.5207\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2608 - accuracy: 0.4967\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.2666 - accuracy: 0.5207\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.2240 - accuracy: 0.5250\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 1.2881 - accuracy: 0.5261\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 1.2475 - accuracy: 0.5272\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 1.2128 - accuracy: 0.5217\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2618 - accuracy: 0.5109\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2169 - accuracy: 0.5261\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2610 - accuracy: 0.5261\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2498 - accuracy: 0.5174\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2672 - accuracy: 0.5185\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2230 - accuracy: 0.5196\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2554 - accuracy: 0.5109\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2308 - accuracy: 0.5228\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2806 - accuracy: 0.4978\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 1.2315 - accuracy: 0.5370\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2441 - accuracy: 0.5315\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 1.2226 - accuracy: 0.5272\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2985 - accuracy: 0.5130\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2413 - accuracy: 0.5065\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2118 - accuracy: 0.5337\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2099 - accuracy: 0.5402\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1853 - accuracy: 0.5391\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5293\n",
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2431 - accuracy: 0.5207\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2004 - accuracy: 0.5380\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2068 - accuracy: 0.5217\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 1.2101 - accuracy: 0.5283\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2207 - accuracy: 0.5293\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 1.1957 - accuracy: 0.5348\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 1s 10ms/step - loss: 1.2279 - accuracy: 0.5261\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 1.2097 - accuracy: 0.5228\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 1.1922 - accuracy: 0.5457\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 1.2300 - accuracy: 0.5293\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.1876 - accuracy: 0.5652\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.1916 - accuracy: 0.5239\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.1936 - accuracy: 0.5402\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1840 - accuracy: 0.5174\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2029 - accuracy: 0.5283\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1667 - accuracy: 0.5609\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1916 - accuracy: 0.5446\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 1.1899 - accuracy: 0.5522\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 1.2043 - accuracy: 0.5261\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2062 - accuracy: 0.5467\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1444 - accuracy: 0.5543\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1691 - accuracy: 0.5467\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2003 - accuracy: 0.5402\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1471 - accuracy: 0.5337\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1825 - accuracy: 0.5207\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1975 - accuracy: 0.5228\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1922 - accuracy: 0.5272\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1770 - accuracy: 0.5446\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1526 - accuracy: 0.5543\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1636 - accuracy: 0.5424\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1605 - accuracy: 0.5500\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1695 - accuracy: 0.5446\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.1669 - accuracy: 0.5380\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1417 - accuracy: 0.5609\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1777 - accuracy: 0.5402\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1700 - accuracy: 0.5326\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.2087 - accuracy: 0.5380\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1693 - accuracy: 0.5478\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1770 - accuracy: 0.5293\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.1378 - accuracy: 0.5598\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 1.1485 - accuracy: 0.5435\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1535 - accuracy: 0.5641\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1881 - accuracy: 0.5391\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1475 - accuracy: 0.5630\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2009 - accuracy: 0.5620\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1573 - accuracy: 0.5337\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1235 - accuracy: 0.5717\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1269 - accuracy: 0.5641\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1279 - accuracy: 0.5696\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.2021 - accuracy: 0.5109\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1473 - accuracy: 0.5478\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1866 - accuracy: 0.5457\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1141 - accuracy: 0.5489\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1529 - accuracy: 0.5359\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1259 - accuracy: 0.5630\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.1194 - accuracy: 0.5674\n",
      "Epoch 171/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.0961 - accuracy: 0.5891\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1185 - accuracy: 0.5848\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1201 - accuracy: 0.5533\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1405 - accuracy: 0.5522\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1189 - accuracy: 0.5467\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0877 - accuracy: 0.5620\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1064 - accuracy: 0.5565\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1123 - accuracy: 0.5630\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1428 - accuracy: 0.5543\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.5728\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1090 - accuracy: 0.5685\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1389 - accuracy: 0.5467\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0907 - accuracy: 0.5880\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1127 - accuracy: 0.5880\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1084 - accuracy: 0.5804\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0934 - accuracy: 0.5848\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1190 - accuracy: 0.5815\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0931 - accuracy: 0.5565\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1170 - accuracy: 0.5804\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0720 - accuracy: 0.5815\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0818 - accuracy: 0.5783\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1142 - accuracy: 0.5880\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1022 - accuracy: 0.5859\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0893 - accuracy: 0.5804\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0847 - accuracy: 0.5946\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.1151 - accuracy: 0.5750\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0697 - accuracy: 0.5848\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1.0743 - accuracy: 0.5630\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0689 - accuracy: 0.5913\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 1.0675 - accuracy: 0.5891\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# # reshaping of dataset # #\n",
    "############################\n",
    "# loading of dataset\n",
    "df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "\n",
    "df.head()\n",
    "dataset = df.values\n",
    "\n",
    "# # df.drop(df[df['Subject']=='andy'].index, inplace=True)\n",
    "# # df.drop(df[df['Subject']=='azfar'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='ch'].index, inplace=True)\n",
    "# # df.drop(df[df['Subject']=='cy'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='gerald'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='jc'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='jonah'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='qikai'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='ys'].index, inplace=True)\n",
    "# df.drop(df[df['Subject']=='zen'].index, inplace=True)\n",
    "\n",
    "\n",
    "# divide data into features X and target (classes) Y\n",
    "# convert target Y to labelbinarizer Y for model\n",
    "X, Y, lb = prepare_dataset(df)\n",
    "\n",
    "# reshaping the dataset to include LSTM Timesteps\n",
    "X = reshape_dataset(X, TIMESTEPS)\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "#####################\n",
    "# # fit the model # #\n",
    "#####################\n",
    "\n",
    "model = create_model()\n",
    "es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
    "                   verbose=0)\n",
    "history = model.fit(X, Y, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b1771e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "# # get model accuracy # #\n",
    "##########################\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "######################\n",
    "# # get model loss # #\n",
    "######################\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d2413",
   "metadata": {},
   "source": [
    "#### SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1247bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # save model # #\n",
    "##################\n",
    "model.model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799eac",
   "metadata": {},
   "source": [
    "# LIVE TESTING\n",
    "> Live test with new dataset to check if model function as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0074460",
   "metadata": {},
   "source": [
    "#### LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1da540d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # load model # #\n",
    "##################\n",
    "\n",
    "# model = create_model()\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f0646",
   "metadata": {},
   "source": [
    "#### LOAD DATA\n",
    "- Import new dataset to verify the model is able to predict accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29bff51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>D|0</th>\n",
       "      <th>I|0+1</th>\n",
       "      <th>PF|0+1</th>\n",
       "      <th>RF|0+1</th>\n",
       "      <th>D|1</th>\n",
       "      <th>I|1+2</th>\n",
       "      <th>PF|1+2</th>\n",
       "      <th>...</th>\n",
       "      <th>RF|6+7</th>\n",
       "      <th>D|7</th>\n",
       "      <th>I|7+8</th>\n",
       "      <th>PF|7+8</th>\n",
       "      <th>RF|7+8</th>\n",
       "      <th>D|8</th>\n",
       "      <th>I|8+9</th>\n",
       "      <th>PF|8+9</th>\n",
       "      <th>RF|8+9</th>\n",
       "      <th>D|9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andy</td>\n",
       "      <td>3</td>\n",
       "      <td>why margin</td>\n",
       "      <td>0.156546</td>\n",
       "      <td>0.305911</td>\n",
       "      <td>0.149060</td>\n",
       "      <td>0.149365</td>\n",
       "      <td>0.156852</td>\n",
       "      <td>0.276707</td>\n",
       "      <td>0.203404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211456</td>\n",
       "      <td>0.157810</td>\n",
       "      <td>0.181083</td>\n",
       "      <td>0.065032</td>\n",
       "      <td>0.023273</td>\n",
       "      <td>0.116051</td>\n",
       "      <td>0.152623</td>\n",
       "      <td>0.033008</td>\n",
       "      <td>0.036572</td>\n",
       "      <td>0.119616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andy</td>\n",
       "      <td>3</td>\n",
       "      <td>war encalm</td>\n",
       "      <td>0.160672</td>\n",
       "      <td>0.335976</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>0.175304</td>\n",
       "      <td>0.225543</td>\n",
       "      <td>0.271715</td>\n",
       "      <td>0.103903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222109</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.239651</td>\n",
       "      <td>0.133426</td>\n",
       "      <td>0.050553</td>\n",
       "      <td>0.106225</td>\n",
       "      <td>0.214052</td>\n",
       "      <td>0.070148</td>\n",
       "      <td>0.107827</td>\n",
       "      <td>0.143904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andy</td>\n",
       "      <td>4</td>\n",
       "      <td>hood whips</td>\n",
       "      <td>0.132462</td>\n",
       "      <td>0.183651</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.081552</td>\n",
       "      <td>0.254179</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060127</td>\n",
       "      <td>0.141966</td>\n",
       "      <td>0.191998</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>0.135546</td>\n",
       "      <td>0.240348</td>\n",
       "      <td>0.090543</td>\n",
       "      <td>0.104802</td>\n",
       "      <td>0.149805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andy</td>\n",
       "      <td>4</td>\n",
       "      <td>shim sweat</td>\n",
       "      <td>0.151514</td>\n",
       "      <td>0.161692</td>\n",
       "      <td>0.042774</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>0.118918</td>\n",
       "      <td>0.178971</td>\n",
       "      <td>0.065487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203171</td>\n",
       "      <td>0.150809</td>\n",
       "      <td>0.246943</td>\n",
       "      <td>0.104717</td>\n",
       "      <td>0.096134</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.237926</td>\n",
       "      <td>0.076469</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.161457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andy</td>\n",
       "      <td>5</td>\n",
       "      <td>henry haji</td>\n",
       "      <td>0.128684</td>\n",
       "      <td>0.227950</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>0.099266</td>\n",
       "      <td>0.136446</td>\n",
       "      <td>0.238963</td>\n",
       "      <td>0.099947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141130</td>\n",
       "      <td>0.160158</td>\n",
       "      <td>0.299132</td>\n",
       "      <td>0.167161</td>\n",
       "      <td>0.138973</td>\n",
       "      <td>0.131971</td>\n",
       "      <td>0.211203</td>\n",
       "      <td>0.059170</td>\n",
       "      <td>0.079232</td>\n",
       "      <td>0.152033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  Class    Sequence       D|0     I|0+1    PF|0+1    RF|0+1  \\\n",
       "0    andy      3  why margin  0.156546  0.305911  0.149060  0.149365   \n",
       "1    andy      3  war encalm  0.160672  0.335976  0.110433  0.175304   \n",
       "2    andy      4  hood whips  0.132462  0.183651  0.102099  0.051189   \n",
       "3    andy      4  shim sweat  0.151514  0.161692  0.042774  0.010178   \n",
       "4    andy      5  henry haji  0.128684  0.227950  0.091504  0.099266   \n",
       "\n",
       "        D|1     I|1+2    PF|1+2  ...    RF|6+7       D|7     I|7+8    PF|7+8  \\\n",
       "0  0.156852  0.276707  0.203404  ...  0.211456  0.157810  0.181083  0.065032   \n",
       "1  0.225543  0.271715  0.103903  ...  0.222109  0.189098  0.239651  0.133426   \n",
       "2  0.081552  0.254179  0.131667  ...  0.060127  0.141966  0.191998  0.056452   \n",
       "3  0.118918  0.178971  0.065487  ...  0.203171  0.150809  0.246943  0.104717   \n",
       "4  0.136446  0.238963  0.099947  ...  0.141130  0.160158  0.299132  0.167161   \n",
       "\n",
       "     RF|7+8       D|8     I|8+9    PF|8+9    RF|8+9       D|9  \n",
       "0  0.023273  0.116051  0.152623  0.033008  0.036572  0.119616  \n",
       "1  0.050553  0.106225  0.214052  0.070148  0.107827  0.143904  \n",
       "2  0.050031  0.135546  0.240348  0.090543  0.104802  0.149805  \n",
       "3  0.096134  0.142226  0.237926  0.076469  0.095700  0.161457  \n",
       "4  0.138973  0.131971  0.211203  0.059170  0.079232  0.152033  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import unseen data\n",
    "pred_df = pd.read_csv(ACTUAL_DATASET_PATH)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "837b9992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################\n",
    "# # check for class validity # #\n",
    "################################\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"Subject\", data=pred_df).set_title(\"Class Validity\")\n",
    "\n",
    "# remove missing values if available\n",
    "pred_df = pred_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b061d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = pred_df.values\n",
    "results = pred_dataset[:,CLASSES_COL_NUM]\n",
    "\n",
    "# # divide data into features X\n",
    "# pred_row = pred_dataset[:,3:].astype(float)\n",
    "\n",
    "#################################\n",
    "# # predict more than one row # #\n",
    "#################################\n",
    "\n",
    "pred_row=pred_df.iloc[:,3:]\n",
    "\n",
    "############################\n",
    "# # predict a single row # #\n",
    "############################\n",
    "\n",
    "# pred_row=pred_df.iloc[11:12,3:]\n",
    "\n",
    "##################\n",
    "# # shape data # #\n",
    "##################\n",
    "pred_row = pred_row.values.tolist()\n",
    "pred_arr = np.asarray(pred_row, dtype=np.float32)\n",
    "pred_arr = np.reshape(pred_arr, (pred_arr.shape[0], TIMESTEPS, pred_arr.shape[1]))\n",
    "\n",
    "Y = CLASS_LIST\n",
    "\n",
    "Y = np.asarray(Y)\n",
    "Y = Y.reshape(-1, 1)\n",
    "lb = LabelBinarizer().fit(Y)\n",
    "Y = lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad543869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Results Prediction    Accuracy\n",
      "0     andy       andy   0.9835091\n",
      "1     andy       andy   0.9874135\n",
      "2     andy       andy   0.9822583\n",
      "3     andy       andy   0.9848643\n",
      "4     andy       andy  0.98559433\n",
      "5     andy      jonah  0.54695404\n",
      "6     andy       andy  0.98700976\n",
      "7     andy       andy   0.9743919\n",
      "8    azfar      azfar    0.757829\n",
      "9    azfar      azfar   0.4639436\n",
      "10   azfar      azfar   0.5808677\n",
      "11   azfar      azfar  0.74418473\n",
      "12   azfar      azfar   0.4270279\n",
      "13   azfar      azfar   0.5381294\n",
      "14   azfar         cy   0.4778775\n",
      "15   azfar        zen   0.6400337\n",
      "16      ch         ch  0.42979214\n",
      "17      ch         ch  0.37672648\n",
      "18      ch         ys  0.37364128\n",
      "19      ch         ch  0.43931246\n",
      "20      ch         ys  0.47063503\n",
      "21      ch         ch  0.37518787\n",
      "22      ch         ys   0.4426484\n",
      "23      ch         jc   0.3265777\n",
      "24      cy      azfar  0.73170424\n",
      "25      cy        zen  0.34133112\n",
      "26      cy         cy  0.44196975\n",
      "27      cy         cy  0.65188146\n",
      "28      cy        zen  0.42162368\n",
      "29      cy      azfar  0.79917765\n",
      "30      cy      azfar   0.6745448\n",
      "31      cy      jonah  0.67780435\n",
      "32  gerald      qikai  0.83689076\n",
      "33  gerald         ch  0.43971613\n",
      "34  gerald     gerald  0.48259377\n",
      "35  gerald         ys  0.36600527\n",
      "36  gerald     gerald  0.83201265\n",
      "37  gerald      qikai   0.9426685\n",
      "38  gerald     gerald   0.9864748\n",
      "39  gerald     gerald  0.49350873\n",
      "40      jc         jc   0.4047578\n",
      "41      jc         ys  0.36729383\n",
      "42      jc      jonah  0.72146624\n",
      "43      jc         jc   0.3384795\n",
      "44      jc         ys  0.47698754\n",
      "45      jc      jonah   0.3563537\n",
      "46      jc         jc  0.37542686\n",
      "47      jc         ys  0.46911633\n",
      "48   jonah         jc  0.31236798\n",
      "49   jonah      jonah  0.29953527\n",
      "50   jonah         jc  0.31284463\n",
      "51   jonah      jonah   0.7178557\n",
      "52   jonah      qikai   0.7338923\n",
      "53   jonah        zen   0.5172425\n",
      "54   jonah      jonah  0.33661053\n",
      "55   jonah         ys  0.41896304\n",
      "56   qikai      qikai  0.92893815\n",
      "57   qikai         ch   0.4401502\n",
      "58   qikai     gerald    0.981509\n",
      "59   qikai         ch  0.39039537\n",
      "60   qikai      qikai   0.9523996\n",
      "61   qikai         ys   0.3866009\n",
      "62   qikai         ch  0.36855802\n",
      "63   qikai      qikai  0.95669514\n",
      "64      ys         ch   0.3641334\n",
      "65      ys         ys  0.45461467\n",
      "66      ys         ys   0.3744024\n",
      "67      ys         ch  0.32888067\n",
      "68      ys         ch  0.42092672\n",
      "69      ys         jc  0.43033898\n",
      "70      ys         ys  0.45737615\n",
      "71      ys         ys  0.47678253\n",
      "72     zen         jc  0.36517322\n",
      "73     zen         jc   0.4032931\n",
      "74     zen      azfar  0.76167095\n",
      "75     zen        zen  0.63592166\n",
      "76     zen       andy  0.98723745\n",
      "77     zen         cy  0.34318063\n",
      "78     zen        zen   0.5741067\n",
      "79     zen      azfar  0.72108763\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# # get prediction and its label # #\n",
    "####################################\n",
    "\n",
    "pred_proba = model.predict(pred_arr)\n",
    "pred = lb.inverse_transform(pred_proba)\n",
    "acc = np.max(pred_proba, axis=1)\n",
    "\n",
    "pred_results = np.column_stack((pred, acc))\n",
    "pred_results = np.column_stack((results, pred_results))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.DataFrame(data=pred_results, index=None, columns=['Results', 'Prediction', 'Accuracy'])\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"results.csv\")\n",
    "\n",
    "#=IF(EXACT(B2, C2), \"Match\", \"Nope\")â€‹"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7d334f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d2798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8af20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3741765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
