{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff04440-8080-4635-ac32-430ac6f7eff4",
   "metadata": {},
   "source": [
    "#### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af71c6bf-604a-4f0c-a18c-6f91bbcf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, \\\n",
    "    BatchNormalization, Flatten, LSTM\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45a7c3",
   "metadata": {},
   "source": [
    "#### PARAMETERS\n",
    "- Set the condition\n",
    "> * N_FEATURES: Number of Features\n",
    "> * CHECK_BLANKS: Check for blank data. If any blank data is found, the whole row of data will be deleted.\n",
    "> * CHECK_CLASS_IMBALANCE: Check for dataset class imbalance. The more balance the dataset, the less biases the model will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7460824",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# # deep learning features # #\n",
    "##############################\n",
    "SEED = 1005 # random seed for reproducibility\n",
    "\n",
    "# should make this dynamic\n",
    "N_FEATURES = 194 #291 #194 #37 #98 #190 #61 #37 #46\n",
    "# N_CLASSES= 9\n",
    "TIMESTEPS = 1\n",
    "EPOCH=200\n",
    "BATCH_SIZE=500\n",
    "\n",
    "###############\n",
    "# # dataset # #\n",
    "###############\n",
    "DATASET_DIR_NAME = \"dataset\"\n",
    "# SAMPLE_DATASET_NAME = \"flm2m_fr97_train\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"flm2m_fr97_test_fixed\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"flm2m_fr97_test_flex\" + \".csv\"\n",
    "SAMPLE_DATASET_NAME = \"flm2m_fr194_train\" + \".csv\"\n",
    "ACTUAL_DATASET_NAME = \"flm2m_fr194_test_fixed\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"flm2m_fr194_test_flex\" + \".csv\"\n",
    "# SAMPLE_DATASET_NAME = \"flm2m_fr291_train\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"flm2m_fr291_test_fixed\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"flm2m_fr291_test_flex\" + \".csv\"\n",
    "\n",
    "\n",
    "MODEL_DIR_NAME = \"model\"\n",
    "MODEL_NAME = \"flm2m_fr194_model\" + \".h5\"\n",
    "RESULT_NAME = \"results_flm2m_fr194_flexixed\" + \".csv\"\n",
    "\n",
    "DATASET_DIR_PATH = os.path.join(os.getcwd(), DATASET_DIR_NAME)\n",
    "SAMPLE_DATASET_PATH = os.path.join(DATASET_DIR_PATH, SAMPLE_DATASET_NAME)\n",
    "ACTUAL_DATASET_PATH = os.path.join(DATASET_DIR_PATH, ACTUAL_DATASET_NAME)\n",
    "\n",
    "MODEL_DIR_PATH = os.path.join(os.getcwd(), MODEL_DIR_NAME)\n",
    "MODEL_PATH = os.path.join(MODEL_DIR_PATH, MODEL_NAME)\n",
    "\n",
    "CLASSES_COL_NAME = \"Subject\"\n",
    "CLASSES_COL_NUM = 0\n",
    "FEATURES_COL_NUM = 2 #6 #4\n",
    "# CLASS_LIST = ['adhy', 'alan', 'andy', 'bryce', 'chris', 'cy', 'gerald', 'jc', 'jonah', 'qk']\n",
    "CLASS_LIST = ['adhy', 'andy', 'bryce', 'chris', 'cy', 'hr', 'jc', 'ys']\n",
    "# CLASS_LIST = ['andy', 'azfar', 'gerald', 'jonah', 'ys']\n",
    "\n",
    "#################\n",
    "# # sns theme # #\n",
    "#################\n",
    "# sns.set_theme(style=\"darkgrid\") # (dark background with white gridlines)\n",
    "sns.set_theme(style=\"whitegrid\") # (white background with grey gridlines)\n",
    "# sns.set_theme(style=\"dark\") # (dark background with no gridlines)\n",
    "# sns.set_theme(style=\"white\") # (white background with no gridlines)\n",
    "# sns.set_theme(style=\"ticks\") # (white background with axis ticks and no gridlines)\n",
    "\n",
    "def df_drop(df):\n",
    "#     df.drop(df[df['Subject']=='adhy'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='alan'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='andy'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='bryce'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='chris'].index, inplace=True)\n",
    "#     df.drop(df[df['Subject']=='cy'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='gerald'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='jc'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='jonah'].index, inplace=True)\n",
    "#     df.drop(df[df['Subject']=='qk'].index, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971b4aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory exists at: C:\\Users\\spencer\\Documents\\Github\\deep-captcha\\dataset\n",
      "Model directory exists at: C:\\Users\\spencer\\Documents\\Github\\deep-captcha\\model\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(DATASET_DIR_PATH) is True:\n",
    "    print(f\"Dataset directory exists at: {DATASET_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(DATASET_DIR_PATH, 666)\n",
    "        print(f\"Dataset directory have been created at: {DATASET_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Dataset Directory not created\")\n",
    "        \n",
    "if os.path.isdir(MODEL_DIR_PATH) is True:\n",
    "    print(f\"Model directory exists at: {MODEL_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(MODEL_DIR_PATH, 666)\n",
    "        print(f\"Model directory have been created at: {MODEL_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Model Directory not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52cdd5",
   "metadata": {},
   "source": [
    "#### CREATE MODEL\n",
    "- Create base model\n",
    "- Wrap it with KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f633b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base model\n",
    "def create_base_model():\n",
    "    model = Sequential()\n",
    "#     model.add(LSTM(units=128, return_sequences=True, \n",
    "#                  input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=1024, return_sequences=True,\n",
    "             input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=512, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=256, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    # softmax for multi-class classification\n",
    "    model.add(Flatten())\n",
    "    print(n_classes)\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# wrap model in KerasClassifier\n",
    "def create_model():\n",
    "    model = KerasClassifier(build_fn=create_base_model, epochs=EPOCH, \n",
    "                            batch_size=BATCH_SIZE)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2280ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into features X and target (classes) Y\n",
    "def prepare_dataset(df):\n",
    "    X = df.values[:,FEATURES_COL_NUM:].astype(float)\n",
    "    Y = df.values[:,CLASSES_COL_NUM].astype(str)\n",
    "\n",
    "    # convert target Y to labelbinarizer Y for model\n",
    "    # fit_transform is not used to reuse lb\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    lb = LabelBinarizer().fit(Y)\n",
    "    Y = lb.transform(Y)\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # # get all the encoded class # #\n",
    "    #################################\n",
    "    print(\"LabelBinarizer is able to decipher: \")\n",
    "    print(lb.classes_)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ###########################\n",
    "    # # print X and Y shape # #\n",
    "    ###########################\n",
    "    print(f\"X | Features | Dataset Shape: {X.shape}\")\n",
    "    print(f\"Y | Classes  | Dataset Shape: {Y.shape}\")\n",
    "\n",
    "    return X, Y, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2cd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_shape_dataset(X, Y, SPLIT_RATIO, TIMESTEPS, SEED):\n",
    "\n",
    "    ##############################################################\n",
    "    # # split dataset into train and test set of 0.8/0.2 ratio # #\n",
    "    ##############################################################\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=SPLIT_RATIO, random_state=SEED)\n",
    "\n",
    "    ############################\n",
    "    # # reshaping of dataset # #\n",
    "    ############################\n",
    "\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], TIMESTEPS, X_train.shape[1]))\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], TIMESTEPS, X_test.shape[1]))\n",
    "\n",
    "    # retrieve number of classes\n",
    "    n_classes = y_train.shape[1]\n",
    "\n",
    "    print(f\"X train shape: {X_train.shape}\")\n",
    "    print(f\"Y train shape: {y_train.shape}\")\n",
    "    print(f\"X test shape: {X_test.shape}\")\n",
    "    print(f\"Y test shape: {y_test.shape}\")\n",
    "    print(f\"Number of Classes: {n_classes}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, n_classes\n",
    "\n",
    "def reshape_dataset(X, TIMESTEPS):\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    X = np.reshape(X, (X.shape[0], TIMESTEPS, X.shape[1]))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13daa1c",
   "metadata": {},
   "source": [
    "#### CHECK DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d2ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     sns.catplot(x=\"Subject\", y=\"D|0\", data=df)\n",
    "\n",
    "    \n",
    "#     sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|3\", hue=\"D|3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|4\", hue=\"D|4\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|5\", hue=\"D|5\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|6\", hue=\"D|6\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|7\", hue=\"D|7\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|8\", hue=\"D|8\", data=df, legend=False)\n",
    "# df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "# df.head()\n",
    "# sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"I|1+2\", hue=\"I|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"PF|1+2\", hue=\"PF|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"RF|1+2\", hue=\"RF|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"DT|1+2\", hue=\"DT|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"D|9\", hue=\"D|9\", data=df, legend=False)\n",
    "\n",
    "\n",
    "#     sns.catplot(x=\"Subject\", y=\"TT|1+3\", hue=\"TT|1+3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"QT|1+4\", hue=\"QT|1+4\", data=df, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b17bde",
   "metadata": {},
   "source": [
    "#### FIT AND SAVE MODEL\n",
    "- Fitting of model\n",
    "- Get Accuracy and Loss of Mdoel\n",
    "- Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5703966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelBinarizer is able to decipher: \n",
      "['adhy' 'andy' 'bryce' 'chris' 'cy' 'hr' 'jc' 'ys']\n",
      "\n",
      "\n",
      "X | Features | Dataset Shape: (79200, 194)\n",
      "Y | Classes  | Dataset Shape: (79200, 8)\n",
      "8\n",
      "Epoch 1/200\n",
      "159/159 [==============================] - 42s 178ms/step - loss: 1.2891 - accuracy: 0.5019\n",
      "Epoch 2/200\n",
      "159/159 [==============================] - 30s 190ms/step - loss: 0.9517 - accuracy: 0.6466\n",
      "Epoch 3/200\n",
      "159/159 [==============================] - 31s 193ms/step - loss: 0.7499 - accuracy: 0.7249\n",
      "Epoch 4/200\n",
      "159/159 [==============================] - 31s 196ms/step - loss: 0.5369 - accuracy: 0.8105\n",
      "Epoch 5/200\n",
      "159/159 [==============================] - 31s 196ms/step - loss: 0.3597 - accuracy: 0.8774\n",
      "Epoch 6/200\n",
      "159/159 [==============================] - 33s 204ms/step - loss: 0.2511 - accuracy: 0.9170\n",
      "Epoch 7/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.1661 - accuracy: 0.9448\n",
      "Epoch 8/200\n",
      "159/159 [==============================] - 31s 196ms/step - loss: 0.1257 - accuracy: 0.9594\n",
      "Epoch 9/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0981 - accuracy: 0.9683\n",
      "Epoch 10/200\n",
      "159/159 [==============================] - 31s 196ms/step - loss: 0.0861 - accuracy: 0.9723\n",
      "Epoch 11/200\n",
      "159/159 [==============================] - 31s 196ms/step - loss: 0.0750 - accuracy: 0.9762\n",
      "Epoch 12/200\n",
      "159/159 [==============================] - 31s 194ms/step - loss: 0.0597 - accuracy: 0.9808\n",
      "Epoch 13/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0571 - accuracy: 0.9821\n",
      "Epoch 14/200\n",
      "159/159 [==============================] - 30s 191ms/step - loss: 0.0586 - accuracy: 0.9817\n",
      "Epoch 15/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0459 - accuracy: 0.9861\n",
      "Epoch 16/200\n",
      "159/159 [==============================] - 30s 187ms/step - loss: 0.0437 - accuracy: 0.9867\n",
      "Epoch 17/200\n",
      "159/159 [==============================] - 30s 187ms/step - loss: 0.0417 - accuracy: 0.9872\n",
      "Epoch 18/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 19/200\n",
      "159/159 [==============================] - 31s 195ms/step - loss: 0.0397 - accuracy: 0.9879\n",
      "Epoch 20/200\n",
      "159/159 [==============================] - 31s 195ms/step - loss: 0.0361 - accuracy: 0.9888\n",
      "Epoch 21/200\n",
      "159/159 [==============================] - 31s 197ms/step - loss: 0.0364 - accuracy: 0.9888\n",
      "Epoch 22/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0324 - accuracy: 0.9902\n",
      "Epoch 23/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0321 - accuracy: 0.9900\n",
      "Epoch 24/200\n",
      "159/159 [==============================] - 32s 198ms/step - loss: 0.0312 - accuracy: 0.9901\n",
      "Epoch 25/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0353 - accuracy: 0.9891\n",
      "Epoch 26/200\n",
      "159/159 [==============================] - 31s 195ms/step - loss: 0.0279 - accuracy: 0.9912\n",
      "Epoch 27/200\n",
      "159/159 [==============================] - 31s 195ms/step - loss: 0.0283 - accuracy: 0.9915\n",
      "Epoch 28/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0280 - accuracy: 0.9912\n",
      "Epoch 29/200\n",
      "159/159 [==============================] - 31s 193ms/step - loss: 0.0274 - accuracy: 0.9918\n",
      "Epoch 30/200\n",
      "159/159 [==============================] - 30s 188ms/step - loss: 0.0278 - accuracy: 0.9917\n",
      "Epoch 31/200\n",
      "159/159 [==============================] - 32s 204ms/step - loss: 0.0274 - accuracy: 0.9916\n",
      "Epoch 32/200\n",
      "159/159 [==============================] - 31s 197ms/step - loss: 0.0233 - accuracy: 0.9931\n",
      "Epoch 33/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0266 - accuracy: 0.9920\n",
      "Epoch 34/200\n",
      "159/159 [==============================] - 31s 198ms/step - loss: 0.0250 - accuracy: 0.9925\n",
      "Epoch 35/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0231 - accuracy: 0.9932\n",
      "Epoch 36/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 37/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0290 - accuracy: 0.9913\n",
      "Epoch 38/200\n",
      "159/159 [==============================] - 33s 209ms/step - loss: 0.0234 - accuracy: 0.9933\n",
      "Epoch 39/200\n",
      "159/159 [==============================] - 34s 214ms/step - loss: 0.0224 - accuracy: 0.9932\n",
      "Epoch 40/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0219 - accuracy: 0.9933\n",
      "Epoch 41/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 42/200\n",
      "159/159 [==============================] - 31s 198ms/step - loss: 0.0235 - accuracy: 0.9927\n",
      "Epoch 43/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0207 - accuracy: 0.9935\n",
      "Epoch 44/200\n",
      "159/159 [==============================] - 33s 210ms/step - loss: 0.0261 - accuracy: 0.9924\n",
      "Epoch 45/200\n",
      "159/159 [==============================] - 31s 196ms/step - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 46/200\n",
      "159/159 [==============================] - 34s 211ms/step - loss: 0.0225 - accuracy: 0.9932\n",
      "Epoch 47/200\n",
      "159/159 [==============================] - 33s 210ms/step - loss: 0.0193 - accuracy: 0.9940\n",
      "Epoch 48/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0217 - accuracy: 0.9936\n",
      "Epoch 49/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 50/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0201 - accuracy: 0.9938\n",
      "Epoch 51/200\n",
      "159/159 [==============================] - 32s 198ms/step - loss: 0.0184 - accuracy: 0.9944\n",
      "Epoch 52/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0173 - accuracy: 0.9952\n",
      "Epoch 53/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0168 - accuracy: 0.9951\n",
      "Epoch 54/200\n",
      "159/159 [==============================] - 34s 215ms/step - loss: 0.0207 - accuracy: 0.9939\n",
      "Epoch 55/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0167 - accuracy: 0.9951\n",
      "Epoch 56/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0168 - accuracy: 0.9949\n",
      "Epoch 57/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch 58/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0153 - accuracy: 0.9956\n",
      "Epoch 59/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0193 - accuracy: 0.9942\n",
      "Epoch 60/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0156 - accuracy: 0.9954\n",
      "Epoch 61/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0187 - accuracy: 0.9947\n",
      "Epoch 62/200\n",
      "159/159 [==============================] - 37s 234ms/step - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 63/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0199 - accuracy: 0.9942\n",
      "Epoch 64/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0149 - accuracy: 0.9955\n",
      "Epoch 65/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0163 - accuracy: 0.9951\n",
      "Epoch 66/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 67/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0184 - accuracy: 0.9946\n",
      "Epoch 68/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0134 - accuracy: 0.9961\n",
      "Epoch 69/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0138 - accuracy: 0.9959\n",
      "Epoch 70/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0171 - accuracy: 0.9945\n",
      "Epoch 71/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0176 - accuracy: 0.9950\n",
      "Epoch 72/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 73/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 74/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch 75/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0170 - accuracy: 0.9947\n",
      "Epoch 76/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0178 - accuracy: 0.9945\n",
      "Epoch 78/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 79/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0156 - accuracy: 0.9958\n",
      "Epoch 80/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0174 - accuracy: 0.9947\n",
      "Epoch 81/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0151 - accuracy: 0.9956\n",
      "Epoch 82/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0098 - accuracy: 0.9973\n",
      "Epoch 83/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0133 - accuracy: 0.9960\n",
      "Epoch 84/200\n",
      "159/159 [==============================] - 33s 204ms/step - loss: 0.0177 - accuracy: 0.9947\n",
      "Epoch 85/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 86/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0126 - accuracy: 0.9963\n",
      "Epoch 87/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 88/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 89/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 90/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0126 - accuracy: 0.9965\n",
      "Epoch 91/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0128 - accuracy: 0.9965\n",
      "Epoch 92/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0135 - accuracy: 0.9960\n",
      "Epoch 93/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0139 - accuracy: 0.9955\n",
      "Epoch 94/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 95/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 96/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 97/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0154 - accuracy: 0.9953\n",
      "Epoch 98/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0150 - accuracy: 0.9956\n",
      "Epoch 99/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0125 - accuracy: 0.9964\n",
      "Epoch 100/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0115 - accuracy: 0.9965\n",
      "Epoch 101/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0161 - accuracy: 0.9952\n",
      "Epoch 102/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 103/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0121 - accuracy: 0.9965\n",
      "Epoch 104/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 105/200\n",
      "159/159 [==============================] - 34s 215ms/step - loss: 0.0138 - accuracy: 0.9959\n",
      "Epoch 106/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0127 - accuracy: 0.9965\n",
      "Epoch 107/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0099 - accuracy: 0.9973\n",
      "Epoch 108/200\n",
      "159/159 [==============================] - 35s 219ms/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 109/200\n",
      "159/159 [==============================] - 35s 219ms/step - loss: 0.0098 - accuracy: 0.9971\n",
      "Epoch 110/200\n",
      "159/159 [==============================] - 35s 220ms/step - loss: 0.0151 - accuracy: 0.9957\n",
      "Epoch 111/200\n",
      "159/159 [==============================] - 35s 222ms/step - loss: 0.0104 - accuracy: 0.9968\n",
      "Epoch 112/200\n",
      "159/159 [==============================] - 34s 214ms/step - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 113/200\n",
      "159/159 [==============================] - 35s 217ms/step - loss: 0.0123 - accuracy: 0.9963\n",
      "Epoch 114/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0116 - accuracy: 0.9966\n",
      "Epoch 115/200\n",
      "159/159 [==============================] - 34s 212ms/step - loss: 0.0139 - accuracy: 0.9959\n",
      "Epoch 116/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 117/200\n",
      "159/159 [==============================] - 31s 197ms/step - loss: 0.0145 - accuracy: 0.9962\n",
      "Epoch 118/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0120 - accuracy: 0.9967\n",
      "Epoch 119/200\n",
      "159/159 [==============================] - 35s 221ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 120/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 121/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 122/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 123/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 124/200\n",
      "159/159 [==============================] - 33s 204ms/step - loss: 0.0106 - accuracy: 0.9972\n",
      "Epoch 125/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0138 - accuracy: 0.9960\n",
      "Epoch 126/200\n",
      "159/159 [==============================] - 33s 210ms/step - loss: 0.0131 - accuracy: 0.9960\n",
      "Epoch 127/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 128/200\n",
      "159/159 [==============================] - 33s 210ms/step - loss: 0.0107 - accuracy: 0.9968\n",
      "Epoch 129/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0130 - accuracy: 0.9962\n",
      "Epoch 130/200\n",
      "159/159 [==============================] - 33s 208ms/step - loss: 0.0104 - accuracy: 0.9970\n",
      "Epoch 131/200\n",
      "159/159 [==============================] - 32s 202ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 132/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0071 - accuracy: 0.9977\n",
      "Epoch 133/200\n",
      "159/159 [==============================] - 32s 204ms/step - loss: 0.0103 - accuracy: 0.9969\n",
      "Epoch 134/200\n",
      "159/159 [==============================] - 30s 191ms/step - loss: 0.0139 - accuracy: 0.9960\n",
      "Epoch 135/200\n",
      "159/159 [==============================] - 31s 197ms/step - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 136/200\n",
      "159/159 [==============================] - 34s 213ms/step - loss: 0.0098 - accuracy: 0.9971\n",
      "Epoch 137/200\n",
      "159/159 [==============================] - 31s 195ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 138/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 139/200\n",
      "159/159 [==============================] - 31s 198ms/step - loss: 0.0091 - accuracy: 0.9974\n",
      "Epoch 140/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0093 - accuracy: 0.9975\n",
      "Epoch 141/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0160 - accuracy: 0.9953\n",
      "Epoch 142/200\n",
      "159/159 [==============================] - 30s 191ms/step - loss: 0.0116 - accuracy: 0.9969\n",
      "Epoch 143/200\n",
      "159/159 [==============================] - 32s 204ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 144/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0087 - accuracy: 0.9974\n",
      "Epoch 145/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0090 - accuracy: 0.9973\n",
      "Epoch 146/200\n",
      "159/159 [==============================] - 31s 192ms/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 147/200\n",
      "159/159 [==============================] - 30s 191ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 148/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 149/200\n",
      "159/159 [==============================] - 35s 219ms/step - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 150/200\n",
      "159/159 [==============================] - 36s 226ms/step - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 151/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0105 - accuracy: 0.9970\n",
      "Epoch 152/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 153/200\n",
      "159/159 [==============================] - 34s 214ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 34s 212ms/step - loss: 0.0147 - accuracy: 0.9954\n",
      "Epoch 155/200\n",
      "159/159 [==============================] - 33s 211ms/step - loss: 0.0155 - accuracy: 0.9953\n",
      "Epoch 156/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 157/200\n",
      "159/159 [==============================] - 35s 219ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 158/200\n",
      "159/159 [==============================] - 34s 214ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 159/200\n",
      "159/159 [==============================] - 33s 210ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 160/200\n",
      "159/159 [==============================] - 33s 208ms/step - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 161/200\n",
      "159/159 [==============================] - 32s 204ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 162/200\n",
      "159/159 [==============================] - 33s 210ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 163/200\n",
      "159/159 [==============================] - 33s 206ms/step - loss: 0.0112 - accuracy: 0.9968\n",
      "Epoch 164/200\n",
      "159/159 [==============================] - 34s 215ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 165/200\n",
      "159/159 [==============================] - 32s 204ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 166/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 167/200\n",
      "159/159 [==============================] - 33s 208ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "Epoch 168/200\n",
      "159/159 [==============================] - 33s 208ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 169/200\n",
      "159/159 [==============================] - 34s 212ms/step - loss: 0.0089 - accuracy: 0.9974\n",
      "Epoch 170/200\n",
      "159/159 [==============================] - 30s 191ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 171/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 172/200\n",
      "159/159 [==============================] - 33s 208ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 173/200\n",
      "159/159 [==============================] - 31s 194ms/step - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 174/200\n",
      "159/159 [==============================] - 31s 194ms/step - loss: 0.0105 - accuracy: 0.9972\n",
      "Epoch 175/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 176/200\n",
      "159/159 [==============================] - 31s 194ms/step - loss: 0.0068 - accuracy: 0.9980\n",
      "Epoch 177/200\n",
      "159/159 [==============================] - 30s 187ms/step - loss: 0.0088 - accuracy: 0.9974\n",
      "Epoch 178/200\n",
      "159/159 [==============================] - 31s 197ms/step - loss: 0.0121 - accuracy: 0.9965\n",
      "Epoch 179/200\n",
      "159/159 [==============================] - 30s 189ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 180/200\n",
      "159/159 [==============================] - 31s 197ms/step - loss: 0.0054 - accuracy: 0.9984\n",
      "Epoch 181/200\n",
      "159/159 [==============================] - 30s 190ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 182/200\n",
      "159/159 [==============================] - 30s 188ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "Epoch 183/200\n",
      "159/159 [==============================] - 30s 189ms/step - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 184/200\n",
      "159/159 [==============================] - 33s 208ms/step - loss: 0.0061 - accuracy: 0.9982\n",
      "Epoch 185/200\n",
      "159/159 [==============================] - 31s 192ms/step - loss: 0.0115 - accuracy: 0.9968\n",
      "Epoch 186/200\n",
      "159/159 [==============================] - 32s 203ms/step - loss: 0.0093 - accuracy: 0.9974\n",
      "Epoch 187/200\n",
      "159/159 [==============================] - 31s 197ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 188/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 189/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 190/200\n",
      "159/159 [==============================] - 34s 216ms/step - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 191/200\n",
      "159/159 [==============================] - 38s 239ms/step - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 192/200\n",
      "159/159 [==============================] - 32s 200ms/step - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 193/200\n",
      "159/159 [==============================] - 30s 189ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 194/200\n",
      "159/159 [==============================] - 31s 195ms/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 195/200\n",
      "159/159 [==============================] - 33s 207ms/step - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 196/200\n",
      "159/159 [==============================] - 34s 216ms/step - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 197/200\n",
      "159/159 [==============================] - 32s 199ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 198/200\n",
      "159/159 [==============================] - 33s 205ms/step - loss: 0.0077 - accuracy: 0.9978\n",
      "Epoch 199/200\n",
      "159/159 [==============================] - 35s 222ms/step - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 200/200\n",
      "159/159 [==============================] - 32s 201ms/step - loss: 0.0081 - accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# # reshaping of dataset # #\n",
    "############################\n",
    "# loading of dataset\n",
    "df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "df.head()\n",
    "\n",
    "# df = df_drop(df)\n",
    "dataset = df.values\n",
    "\n",
    "# divide data into features X and target (classes) Y\n",
    "# convert target Y to labelbinarizer Y for model\n",
    "X, Y, lb = prepare_dataset(df)\n",
    "\n",
    "# reshaping the dataset to include LSTM Timesteps\n",
    "X = reshape_dataset(X, TIMESTEPS)\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "#####################\n",
    "# # fit the model # #\n",
    "#####################\n",
    "\n",
    "model = create_model()\n",
    "es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
    "                   verbose=0)\n",
    "history = model.fit(X, Y, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1771e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEXCAYAAACtTzM+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzgUlEQVR4nO3deXxU1f3/8ddMZslCQkxIwiqLiiCRpaBEVBYtBjABqrRC/YGIpWpttbTfFrTwFWhRXFpaW1dabSv4ENzFWkDhW1sJVUllLQiyQyAhCWSdfc7vjyQjIQkkyCSBeT8fDx/m3jt35jN3Ludzzzn3nmMxxhhERCTiWVs6ABERaR2UEEREBFBCEBGRakoIIiICKCGIiEg1JQQREQGUEOQ8cujQIS6//HJuv/32OtsefPBBLr/8coqLi5v0nnfffTdvvvnmaV/zySefkJWV1eD2hQsXkp6eztGjR5v02SKtjRKCnFecTif79u3j8OHDoXWVlZXk5ua2SDwej4e3336bzMxMlixZ0iIxiJwrSghyXomKimL06NGsWLEitG716tXceOONtV63bNkysrKyGDt2LNOmTWPv3r0A5Ofnc+edd3LzzTczffp0jh07Ftpn9+7dTJs2jVtuuYVx48bx+uuvnzGev/3tb1x88cVMnTqV5cuX43K5Qtv27t3L5MmTufnmm8nOzub9998/7fobbriBLVu2hPavWT506BDDhg1j2rRpZGZmUlBQwHPPPceECRPIzs7mm9/8Jh988AEAfr+fRx99lMzMTMaMGcMvfvELvF4vmZmZfPzxx6H3nj17Nn/5y18afdwlQhiR88TBgwdN//79zZYtW8zo0aND6++44w7zxRdfmJ49e5qioiKTk5NjvvnNb5qioiJjjDFvvPGGGT16tAkGg+YHP/iBWbRokTHGmH379pn+/fubN954w/h8PjNmzBizdetWY4wxpaWlZvTo0ebzzz83//73v83NN99cb0wTJkwwL7/8sjHGmDFjxpilS5eGto0fP94sWbLEGGNMXl6eufHGG01ZWVmD60eMGGE2b94c2r9m+eDBg6Znz57ms88+M8YYc+jQITN58mTjcrmMMca89957JisryxhjzF/+8hdz++23G5fLZQKBgHnggQfMW2+9ZV566SVz//33G2OMKSsrMxkZGaakpORr/BpyIbK1dEISaar09HSsVitbt24lOTmZiooKevbsGdr+r3/9izFjxpCUlATALbfcwoIFCzh06BA5OTnMnDkTgK5duzJ48GAA9u3bx4EDB3jooYdC7+N2u/nvf//LJZdcUm8c27ZtY/v27bzwwgsAjB8/nr/+9a9MmjSJkpISduzYwbe//W0AOnTowIcffsiJEyfqXX8mNpuN/v37A9CpUycee+wxVqxYwf79+9m0aRMVFRUA5OTkMG7cOKKjowH47W9/C0BpaSlPP/00xcXFrFy5kuHDh5OQkHDmgy0RRQlBzktjx47l3XffJSkpiXHjxtXaZuoZnssYg9/vx2Kx1Npus1X9EwgEAiQkJPDOO++EthUWFhIfH8/GjRvrjeGVV17BZrNx6623AlXNNQUFBfzzn/9k4MCBAFgsltDr9+zZQ0pKSr3rO3bsWCd2r9cb+tvhcIRi3bZtGz/4wQ+YOnUq1157LVdddRXz5s2r9X1O/g7BYJDU1FRGjRrFu+++y4oVK3j44Yfr/U4S2dSHIOelcePGsXLlSt5///06dwBdd911vP/++6E7jt544w0SExPp2rUr119/PcuWLQMgLy+PTz75BIDu3bvjdDpDCeHIkSNkZWWxdevWej+/tLSUv/3tbzz33HOsXbuWtWvX8s9//pOxY8fy5z//mTZt2tCnTx/efvvt0PtNmjQJt9td7/qysjKSkpJCn7dx48Za/Rsn++yzz0hPT+fOO+/k6quvZs2aNQQCAQCuueYa3nvvPbxeL8FgkLlz5/K3v/0NgNtvv52//vWvGGPo27fv2Rx2ucCphiDnpbS0NC655BLi4+NJTEyste3aa69l6tSp3HHHHQSDQZKSknj++eexWq08/PDDPPjgg4wePZr27dvTq1cvoOoK/JlnnmHBggX88Y9/xO/388ADDzBw4MBQ0jjZW2+9xSWXXEJGRkat9ffeey8333wzO3fu5Ne//jXz5s3j5ZdfxmKxsGDBAlJSUhpc/z//8z/MnTuXZcuW0adPH/r06VPvd8/KymL16tWMGTMGu93ONddcQ0lJCeXl5UycOJHDhw9zyy23YIzh6quvZvLkyQD06tWLtm3bMnHixHPwC8iFyGLqq1+LyAXnwIEDTJ48mZUrVxITE9PS4UgrpCYjkQjwu9/9jkmTJjFz5kwlA2mQaggiIgKohiAiItWUEEREBDhP7zIKBoNUVFRgt9tr3c8tIiINM8bg8/mIi4vDaq1bHzgvE0JFRQU7d+5s6TBERM5LPXv2JD4+vs768zIh2O12oOpLORyOJu+/detW0tPTz3VY50RrjU1xNU1rjQtab2yKq2nOJi6v18vOnTtDZeipzsuEUNNM5HA4cDqdZ/UeZ7tfc2itsSmupmmtcUHrjU1xNc3ZxtVQU7s6lUVEBFBCEBGRaudlk9HpBINBDh06FBoOuD42m43t27c3Y1SN19TY4uLi6Ny5c713DIiINEXYE0LNgFvPPfccnTt3rrVt+/btzJ49m/LycgYNGsS8efPqDN/bVIWFhVgsFi6//PIGC8mKigri4uK+1ueES1NiCwaDHD58mMLCQlJTU8McmYhc6MJ6Wblp0yYmTZrEvn376t3+s5/9jDlz5rBq1SqMMSxfvvxrf+aJEydIS0uLiCtmq9VKWloaJSUlLR2KiFwAwlpqLl++nIcffrjeq9fDhw/jdrtDs0DdcsstrFy58mt/ZiAQaPCWqguR3W7H7/e3dBgicgEIa5PRggULGtxWUFAQmj0KICUlhfz8/Ca9f32Tl9hsNiorK8+47+n6GFpaU2Pzer3k5uaGKZqvhPszgsaAAau1cU+fV7gD+ALmtHEdKvSSV+zlkg7RJMdXne578914fIZ2CTYCQWgbG0W0o+rayOsPUloZwB8w2KIsJMbZsEVVxeMLGA4e83CiIkBCbBRd2jlw2qv28wcMJyr8BIJwUZso7FEW3l6Vg8sTJMZpJRCA2Ggr7eJtnKgMkH/cR3GZnzYxVuxRFiq9QbqlOkmIjeLgMS9FZX6CxnBxipMoq4Vg0JCcYMPtNZS7A8Q5rfiDUO4KUOYK4PIGCQQNiXE27DYLXp/B6w/i8xsCQejczkGHJDtur+GTL8p4M+cDuqU56XCRHYfNwrFSP8dKfJyoCODxBWkbZ6NzsoNOyQ7cviAFJ3y4fUHKKgNUeIKkJNixWuF4uR9/ANIS7fTvEUtRqZ8DhR5KKwMEg1W/QSBo2F/godwdpHuak5S2Npx2Kz6/wes3BIOG2GgrwSCs2bSWSk+QTskO+nePxWq14PYF2ba/ku0H3Rw94aXSHSQxzkZqoo20RDvd06KJssIXh93ERVtJiI2iwh2kwh3A5TUYY6hwB/EHDb07x2CxQF6xj+PlfmIcVuJjo/jvgUrKXEHaRFvpmuqkU7IDu83CvnwPFe4Af89dQ+dkB067hb35Hvbme6j0BLk4xUEgWHXu9usex6FCDwePebm0YzQxDitlrgBRVgu2qKpbPd3eIC5PkEpPkHJ3AGMg2mEl2m6p+n/1f15fkMJSP8nxNtrERHGg+rzz+Q1J8TZG9E0gta39nP+bbLFO5foGWW3qMBTp6el17sPdvn37Gdvgm6sPoaysjJkzZ/LMM8806vVbtmxhyZIlPPbYY036HIfDQb9+/c4mRIpKXMQ4bUQ7bOQVlmOLsmK3Wdl3pBSHPYq2cQ4OFpSzPncH2NtiMHRs14YruiexY18xRaVurFYLew+XcLzMQ4zTRv+eKbRLjGHzrkLatnGQ3DaGSo+PtKRYHLYoPtl2FIC4aDvHy9xcFB9NfKydf248TFmll4vinVzdpwMdkmMpOO6i4Hglx467KCpxY4uy0C4xhi5p8azbXIDHG2DEwM4cLapk9+ESYqNtXNo5kQ7t4ti2p4g9h79qTuvRsS0JcQ427iqsdQxinDau69eRLw4c58DRslrbLBZIbhuD3WaloLiSQPCr89Zhj6JX14uocPs4cLQMnz8YWh8fbaGorG7NzWqB4GnGF7ZFWfAHwjcAscUCxkBCnIPN++peOLVt4yDGaWP7wfJa37WG1VJ1vDa4qy5a7DYrtigrn+4s56NtFZRWeEOfExVK7BYu65JI987RbNldyKa9tT+3JiaouhiIcdrI/bKC3D1eUhJj2bG/GLc3QPvkWAandyKxjZMjRRXsP1LKzm1lfLS1LLRv8KSYLRaIjbZjqf5evoDhnU+OAxDjjKJ9chwHijyc2FdJv8va0b1jW44dd7H5y2OhGONj7cQ54WCRi0++KAfAFmWld7ckEto42L63mBinDZfHx/J/FWG1wMXtE/i/zaWh43XyYbRaLcTH2omPdZCYEEuU1UKFy0dhuZ9yl48Kt49g0GCxQMpFsWw/VE4waEhKiKZLWgJ2WxRFJS7ad+pBsPxgaKrWxvJ4PA3OAggtmBDS0tIoLPzqH+axY8cuuI7RmonWG+uKPn146Bdz8HgDREVZ8AeCBAJVJ4fFYsHnD1JW6cVqsRDjjCIQNPj9QU6Uebhn4Yd0Sonnhqu68OGnB9ibV1UQ1vyTtFotJLeNwRjDviOldE6Lx2mPYtueIiyWqkLM4w00GFvVCRrAaoGPNx4maKpO9oQ2Tnz+IF3bx9O7WxInyj289/Ee/AFDh3ZxfHHAR0m5l2hHFO7q92+fHEtstJ2D+WUkxjvZsruQknIPGekd6JIWz+Fj5azdcBCvL0BcjJ3Ui2JIvSiW3t2SCBrDoYJyPt6UR0af9rgrS/jo88N0SI5jVEZXXB4/2/YUsWnXMS7rksj08ekM6JlK7o4C1m06zJ68Eu7M6sMV3ZPIKyzHHhXFui15rPnsAL27J3P7qF6kJcUS7Yii0u0nv7iS/OJKvL4A1/XrSO9uSXROjSe/uIKczUfYffgEbeOc3HxtVYFii7Lw373FbPsyj0mj+tC1QwLllT7sUVaOnXBxqKCM9slxdO+YQKfUeI6XuvH5g0Q7ovj0v0c5Ueah72UpdO+QQCBo2L63GEt1w+7B/HLiY+0kt42mpNyL3WblooRokhKqEmqU1UrB8crQ+8U4bUQ7bRhj2LSrkLzCqgItyV7C6BsGczC/jIP55bg8fjqntaFLajxxMVXNrR5fgD2HSth18DhxMXZ6dGpLfKyDtm2c2KIsFJW4MQbaJUYD8Om2o3zw6QGu6J7MkL4dSEmMISqq/hZpt8dPpcdPtCMKp8OGBSir9LJly2auzRgEwMcb81j1yT5cHj/X9evE6CHduKxLYp2Lxkq3j407j+HxBRjcpz0eX4ATZR4S2zhJiHPUisEYw+5DJdhtVrqkxWO1Vs2v7fEGiHZ+VRQGg4aScg/lLh8d28WxcePn9O8/gN2HS3B7/VzeNQmnPapWHP5AkI07j9GhXRydUtpQXOrGmKqC3BjwBYIEAkFinLbTXvgaY3B5/FitFqIdNipcPsoqvaQlxdbZLzf3YIPvc7aaZT6EG264gb/+9a917jLKyspi3rx5DBw4kNmzZ9OtWze+973vnfH9arJcQzWE3r17n3b/5qoh3HPPPXz88ccMGzaM3bt3k5h4EXa7nbkLnuCxR+ZzrCCfoqJjDBgwiF88/Es+XreepX/5Iwt/8yyzfnIvPXtdwbYtGyktOcHdP/wpg64egt1mrZowPmCwAFFRFo4c3MNHO3xs3lVIuctHQpyDq65Iw3rSCeQPBCk84SZoDF3bx7M3r5Ryl49hAzphgNIKLz06tgUMbm+Arh0S8FUnmy5pbSjM+5JrBl8FwIkyD18eOsFlXRJp26buk5JllV5cbj+pSbEYYwiaqqvFwhMuKlw+Lm4fX+vkNsYQCBpsJ/3j9fgCBAJBYqNP3x+Um5tLet/+OGzWOu/ZlBpnMGga3VTVGLm5uU2+emsurTU2xdU0ZxPX6cpOaIEawvTp07n//vu58sorefLJJ5k9ezYVFRVcccUVTJky5Zx+1toNB/jg0wN11gcCAaKiourZo/FGXn0xNwy6OLRsjMHnD+LzB/H6A7jcfu74/gP8d/sO/t+0HzL1u+P505LfkNa+Ix/9YzXde1zGQw8/itfr5ftTbyP3P5uIjbZjj6q6gnbYrThtsGzZMj76x//x3LPPMD7rJqIdVXEHgoYoq6WqXbIkmgfvGEC5y8fW3YX0vbTdGQvSpiot+KqwTox3Mqh3WoOvjY91EB9bNcaUxWKhugmedokxtEusO1uXxWIJtdPXcNqjwN643+jUq7Wa92yKc5kMRM5XzZIQ1q5dG/p78eLFob979erF66+/3hwhhJXfH+TQsfJQGzJUta1GO6oOb0y0naSkJPpecQl2WxR3/r9vs2XLFv6x6k327NlDRXkpbWMtRFmd1W2MDmxRVm4YMYwYp40+V/SitLSEmJOqtacWoABtYuxkpHcI/xcWkQvSBfek8sluGFT7Kr7GuWgy8geClFZ4MAZKyj0EAkFSL4rBYY/CbrNW3VkQKMUWZaVd22hiYmJIiKuqor388susWrWK73znOwwZMoSdO3ee1AH3lZoqneZ8EJHmcEEnhHA5Xuam6ISbms4XC9ChXVyoQ66GzWar9xmBdevWcdttt5Gdnc2uXbvYsWMHwWAwIh6mE5HWSwmhicorvRSecBMXYyMpITrUjm+r546K5ORkOnbsyIMPPlhr/R133MHcuXN58cUXiYuLY8CAARw6dIiLL65bmxERaS5KCE1Q6fZxtLiSGEcU7ZPiztgRabfbefXVV+usv+aaa1i1alW9+9T0sbz88suhdZ07d67VDyMiEg5qo2gkl8fPkcIK7DYr7dudORmIiJxvlBAawe31h57i7ZTSpt7mIRGR851KtjMIBILkHasgymqlo5KBiFzALsjS7Vw+fF1S4SUQNHRIjsVua32HqxkeNBeRCNH6SrivKTo6mqKionNSUBpTNaZJrNOG09H6+t+NMRQVFREdHd3SoYjIBaD1lXJfU+fOnTl06BDHjh1r8DVerxeHw3HG9/J4A5RUeGgb56S06OsNddFYjY2tRnR0dJ0xokREzsYFlxDsdjvdu3c/7Wtyc3MbNVz0r178hD15JSx+aGS9TxKHQ2NjExE51y64JqNzJRAIsvnLQgb2Smu2ZCAi0pKUEBqw6+AJXB4//S5r19KhiIg0CyWEBmzadQyLBa68RAlBRCKDEkIDNu46RveObeudAEZE5EKkhFAPt9fPjn3H6X9ZSkuHIiLSbJQQ6rH/SCn+QJDe3ZNaOhQRkWajhFCPI0WVAHRsF/55l0VEWgslhHocKawAIC1ZCUFEIocSQj2OFlXQrm10vZO3i4hcqJQQ6nGksIL2ai4SkQijhFCPI0UVdFBzkYhEGCWEU7g8fk6UeeigGoKIRBglhFMcLarqUFZCEJFIo4Rwipo7jNqryUhEIowSwilCNQQlBBGJMEoIp8grrCAhzkFcjL2lQxERaVZKCKc4dtxFalJsS4chItLslBBOUVzqJjlBcxSLSORRQjjF8TI3FykhiEgECmtCWLFiBWPGjGHkyJEsXbq0zvaPPvqI7OxssrOz+elPf0pFRUU4wzkjfyBISbmXpHjNgSAikSdsCSE/P59Fixbxyiuv8M4777Bs2TK+/PLL0PbS0lJmzZrFokWLWLFiBb169WLRokXhCqdRTpR5AEhUDUFEIlDYEkJOTg4ZGRkkJiYSGxtLZmYmK1euDG3ft28fHTt25NJLLwVgxIgRfPjhh+EKp1GOl7kBVEMQkYgUtoRQUFBASspXM46lpqaSn58fWu7WrRtHjx5lx44dAPz973+nsLAwXOE0yvHSqhqC+hBEJBLZwvXGxpg66ywWS+jvhIQEHnvsMebMmUMwGOQ73/kOdnvT7v3funXrWceXm5tbZ93nX5YDcGj/TsqOhe3QnFF9sbUGiqtpWmtc0HpjU1xNc67jClupl5aWxoYNG0LLBQUFpKamhpYDgQDt27fntddeA2Dbtm106dKlSZ+Rnp6O09n05p3c3FwGDhxYZ/3Owh3ACa6/5irstpa5Aauh2Fqa4mqa1hoXtN7YFFfTnE1cHo/ntBfSYSv1hgwZwvr16ykuLsblcrF69WqGDh0a2m6xWJg2bRr5+fkYY3jxxRcZM2ZMuMJplOIyDwlxjhZLBiIiLSlsJV9aWhozZsxgypQpjB8/nqysLPr27cv06dPZsmULVquV+fPn873vfY9Ro0YRHx/PXXfdFa5wGuV4qZsk9R+ISIQKa0N5zTMGJ1u8eHHo7+HDhzN8+PBwhtAkx8vcXKQ7jEQkQqlt5CTFpR7dYSQiEUsJoZoxhhOqIYhIBFNCqFZa4cUfMOpDEJGIpYRQ7XiZHkoTkcimhFCtrNILQEKco4UjERFpGUoI1SpdPgDiojVTmohEJiWEahVuPwCxMS03ZIWISEtSQqhW6a6qIcQ6VUMQkcikhFCtsrqGEKcagohEKCWEapVuH3abFbstqqVDERFpEUoI1SrcfmKjVTsQkcilhFCt0uUjVncYiUgEU0KoVunxE6cagohEMCWEahWqIYhIhFNCqFbp9qkPQUQimhJCtUqPXzUEEYloSgjVKl0+4mKUEEQkcikhAMGgqa4hqMlIRCKXEgLg9voxRsNWiEhkU0JAw1aIiIASAgAVNQPbqVNZRCKYEgJQ6aquISghiEgEU0IAKj01NQQ1GYlI5FJC4KsaghKCiEQyJQS+6kPQcwgiEsmUEDhptjT1IYhIBFNCoOq2U6sFoh2aHEdEIpcSAlVNRjHRdiwWS0uHIiLSYpQQqKohaC4EEYl0SgjUDH2t/gMRiWxKCFTVEHTLqYhEurAmhBUrVjBmzBhGjhzJ0qVL62zftm0bt956K2PHjuXuu++mtLQ0nOE0yOXxE+1UQhCRyBa2hJCfn8+iRYt45ZVXeOedd1i2bBlffvllrdcsWLCA+++/n3fffZfu3bvzpz/9KVzhnJbbGyDGoYQgIpGtUQnhRz/6ETk5OU1645ycHDIyMkhMTCQ2NpbMzExWrlxZ6zXBYJCKigoAXC4X0dHRTfqMc8Xt9ePULaciEuEalRBuuukmnnnmGTIzM/nTn/7EiRMnzrhPQUEBKSkpoeXU1FTy8/NrvWbWrFn84he/4LrrriMnJ4eJEyc2LfpzxO0JEKMmIxGJcBZjjGnsi3fv3s0bb7zBBx98QP/+/Zk8eTJ9+/at97XPPfccLpeLGTNmAPDaa6+xZcsW5s+fD4Db7ebWW2/l0UcfpW/fvrz00kusX7+eF1544YxxeDwetm7d2tiwz+iXrx4i4/I2jByQeM7eU0SktUpPT8fpdNZZ3+jL4mAwyP79+9m3bx9+v5/k5GTmzp3LNddcw89+9rM6r09LS2PDhg2h5YKCAlJTU0PLO3fuxOl0hhLKbbfdxu9+97tz8qXOJDc3l4EDBwIQCAQJvHKIbl07M3Dg5U1+r3Pt5NhaE8XVNK01Lmi9sSmupjmbuM50Md2oJqNFixYxbNgw/vjHPzJmzBhWr17NrFmzWLJkCa+//nq9+wwZMoT169dTXFyMy+Vi9erVDB06NLS9a9euHD16lD179gCwZs0arrzyyqZ8t3PC7Q0AGrZCRKRRNYTi4mIWL15Mr169aq2PjY3l17/+db37pKWlMWPGDKZMmYLP52PChAn07duX6dOnc//993PllVfy6KOP8uMf/xhjDMnJyTzyyCNf/xs1kdtbNfR1tO4yEpEI16hS8L777uO5555j7ty57NmzhyeffJJ58+aRkpLCdddd1+B+2dnZZGdn11q3ePHi0N/Dhg1j2LBhZxn6uaEagohIlUY1Gc2aNYsePXoA0KlTJ66++moeeuihsAbWXNye6hqC7jISkQjXqIRw/PhxpkyZAoDT6WTq1KkcO3YsrIE1F9UQRESqNCohBAKBWs8QFBYW0oS7VVu1UB+CaggiEuEaVQpOnTqV8ePHc/3112OxWMjJyeHnP/95uGNrFm5PTQ1BCUFEIlujSsEJEyaQnp7Ov//9b6Kiorjrrrvo2bNnuGNrFl/dZaQmIxGJbI2+LG7fvj2ZmZkYYwgEAqxbt45rr702nLE1i1CnsmoIIhLhGlUK/u53vwsNKWGz2fB6vVx66aWsWLEirME1h1CnslM1BBGJbI3qVH7nnXf4v//7PzIzM1m1ahULFy7k0ksvDXdszcLl9WOxgNOuhCAika1RCSEpKYnU1FR69OjBjh07GDduHPv37w93bM3C4w0Q7YjCYrG0dCgiIi2qUQnBZrNx4MABevTowYYNG/D7/S02u9m55vL4car/QESkcQnhnnvuYc6cOQwfPpwPPviA4cOHk5GREe7YmoVHs6WJiACN7FT2+/385S9/AeDtt99m//79XH55yw8VfS5U1RDUfyAi0ujhr2vExMTQq1evC6bNvaYPQUQk0jWqhtCzZ0+effZZBg0aRGxsbGh9nz59whZYc3F5/Zo+U0SERiaETZs2sWnTJl577bXQOovFwpo1a8IWWHPxeANcFN/0WddERC40jUoIa9euDXccLcbl8WtgOxERGpkQXnrppXrX33nnnec0mJZQ1YeghCAi0qiScOfOnaG/vV4vubm5DB48OGxBNSeX169OZRERGpkQHn300VrLxcXFF8Tw18GgUQ1BRKRao247PVVSUhKHDx8+17E0O4+vamC7GA1sJyLS9D4EYwxbt24lOTk5bEE1l5qhrzV0hYjIWfQhAHTo0OGCaDKqGfpaNQQRkSb0IXz22WdcddVVnDhxgg0bNtC+fftwxxZ2NbOlqYYgItKEoSueeuopANxuNy+88ALPPPNMWANrDjXzKWtwOxGRRiaENWvW8OKLLwJVU2kuWbKE999/P6yBNQdXqIagJiMRkUYlBJ/Ph91uDy3b7fYLYnC7mk7l2GjVEEREGlUSfuMb3+CnP/0pEyZMwGKx8Pbbb9OvX79wxxZ2ruqEoOcQREQamRDmzJnDU089xaOPPorNZmPIkCHcd9994Y4t7GpqCBrtVESkkQkhNjaWG2+8kVmzZoXuMoqJiQl3bGFXWVND0G2nIiIRfpeRN4DVAk67EoKISGTfZVQ99PWF0EEuIvJ1NarJ6GzvMlqxYgXPPvssPp+PqVOncvvtt4e2bd++nVmzZoWWi4uLadu2Le+9915T4v9a3B7NliYiUuOs7jJ66623zniXUX5+PosWLeLNN9/E4XAwceJEBg8ezKWXXgpA7969eeeddwBwuVx8+9vfZu7cuV/v2zRRpRKCiEhIo5qM5syZQ0pKCgsXLuTxxx8nJSWF2bNnn3afnJwcMjIySExMJDY2lszMTFauXFnva59//nmuuuoqBg0a1PRv8DW4NVuaiEhIoxLCF198wb59+2jbti1xcXF8/vnnjBo16rT7FBQUkJKSElpOTU0lPz+/zutKS0tZvnw5P/zhD5sY+tfn8viJVUIQEQEa2WQ0e/Zsxo0bx6pVq5g4cSJr1qzhpptuOu0+xpg66+rrd1ixYgXf/OY3z2o47a1btzZ5nxq5ubkUnygjITaK3Nzcs36fcGht8dRQXE3TWuOC1hub4mqacx1XoxKCxWLh+9//PsePH6dHjx6MHTuWSZMmnXaftLQ0NmzYEFouKCggNTW1zus+/PBD7r777iaGXSU9PR2n09nk/XJzcxk4cCCWVR/SIfUiBg4ceFafHw41sbU2iqtpWmtc0HpjU1xNczZxeTye015IN6rJKC4uDoCLL76YXbt24XQ6CQQCp91nyJAhrF+/nuLiYlwuF6tXr2bo0KG1XmOMYdu2bQwYMKAxYZxzLq9fD6WJiFRrVELo27cvP/7xj8nIyODFF19k4cKFREWdviBNS0tjxowZTJkyhfHjx5OVlUXfvn2ZPn06W7ZsAapuNbXb7Wd1lX8uuHSXkYhISKNKw4ceeohNmzbRvXt3HnroIXJycnjyySfPuF92djbZ2dm11i1evDj0d3JyMuvWrWtiyOdGIGjweAPqVBYRqdboPoT+/fsDMHz4cIYPHx7GkJqHx1szjpESgogINLLJ6ELk0kinIiK1RHxCUA1BRKRKxCcE9SGIiFSJ2ITg9lTdNqvbTkVEqkRsQlAfgohIbUoISggiIoASghKCiEi1iE0Ibq8SgojIySI2IbjcVQnB6VBCEBGBSE4I3gBORxRRVs2nLCICkZwQPH5iVDsQEQmJ2ITg1kinIiK1RGxC0NDXIiK1RXRC0FPKIiJfifCEoBqCiEiNiE0IXl8Ap101BBGRGhGbEPyBIPaoiP36IiJ1RGyJ6PMHsdki9uuLiNQRsSWizx/EroQgIhISsSWiEoKISG0RWyL6AkFs6kMQEQmJ2BLRrxqCiEgtEVkiBo0hEDTYbbrtVESkRkQmhEDVdMqqIYiInCQiS0R/0ABKCCIiJ4vIEjEQqEoI6lQWEflKRJaIqiGIiNQVkSViIFj1fyUEEZGvRGSJWNNkpIQgIvKViCwRQ01G6kMQEQkJa4m4YsUKxowZw8iRI1m6dGmd7Xv27GHy5MmMHTuWu+66i5KSknCGExLqVFYNQUQkJGwlYn5+PosWLeKVV17hnXfeYdmyZXz55Zeh7cYY7r33XqZPn867775L7969eeGFF8IVTi3qVBYRqStsJWJOTg4ZGRkkJiYSGxtLZmYmK1euDG3ftm0bsbGxDB06FIB77rmH22+/PVzh1BLqVI7Sk8oiIjXCNodkQUEBKSkpoeXU1FQ2b94cWj5w4ADt2rVj5syZ/Pe//6Vnz57MmTOnSZ+xdevWs4qtpsnoyy+/oLLYcVbvEU65ubktHUK9FFfTtNa4oPXGpria5lzHFbaEYIyps85isYT+9vv9fPrppyxZsoQrr7yS3/72tyxcuJCFCxc2+jPS09NxOp1Njm3bgX8BcGV6H7p1SGjy/uGUm5vLwIEDWzqMOhRX07TWuKD1xqa4muZs4vJ4PKe9kA5bk1FaWhqFhYWh5YKCAlJTU0PLKSkpdO3alSuvvBKArKysWjWIcNJYRiIidYWtRBwyZAjr16+nuLgYl8vF6tWrQ/0FAAMGDKC4uJgdO3YAsHbtWvr06ROucGrRbaciInWFrckoLS2NGTNmMGXKFHw+HxMmTKBv375Mnz6d+++/nyuvvJKnn36a2bNn43K5aN++PY8//ni4wqkloLuMRETqCFtCAMjOziY7O7vWusWLF4f+7tevH6+//no4Q6iXnlQWEakrIktEf/VtpxrtVETkKxFZIqqGICJSV0SWiP6gwWqBKNUQRERCIrJEDAQNNs2nLCJSS2QmhICai0REThWRpaI/aPQMgojIKSKyVKxqMorIry4i0qCILBX9AaMmIxGRU0RkqRgIqg9BRORUEVkqBlRDEBGpIyJLRX/Q6CllEZFTRGSpGAiqhiAicqqILBX9AQ19LSJyqogsFatqCHpSWUTkZBGcECLyq4uINCgiS0V/QJ3KIiKnishSUc8hiIjUFZGlop5UFhGpKyJLRfUhiIjUFZGlYkAPpomI1BFxpaIxpuo5BNUQRERqibhSMRDUfMoiIvWJuFLR5w8CSggiIqeKuFKxJiFoghwRkdoirlT0B6prCOpUFhGpJeJKRTUZiYjUL+JKRZ8/AIBNg9uJiNQSgQlBNQQRkfpEXKmohCAiUr+IKxVrOpX1pLKISG0RVyqqhiAiUr+wloorVqxgzJgxjBw5kqVLl9bZ/oc//IERI0Ywbtw4xo0bV+9rzjUlBBGR+tnC9cb5+fksWrSIN998E4fDwcSJExk8eDCXXnpp6DVbt27lN7/5DQMGDAhXGHWEEoKajEREaglbqZiTk0NGRgaJiYnExsaSmZnJypUra71m69atLF68mOzsbObPn4/H4wlXOCEJcQ6sVkiMd4b9s0REzicWY4wJxxs///zzVFZWMmPGDABee+01Nm/ezC9/+UsAKioq+PGPf8zs2bPp1KkTs2bNolOnTqHXn47H42Hr1q1nFZcxBq/f4LSrhiAikSk9PR2ns+5FcdiajOrLMxaLJfR3XFwcixcvDi1PmzaNhx56qFEJoUZDX+pMcnNzGThwYJP3aw6tNTbF1TStNS5ovbEprqY5m7jOdDEdtsvktLQ0CgsLQ8sFBQWkpqaGlvPy8nj99ddDy8YYbLaw5ScRETmDsCWEIUOGsH79eoqLi3G5XKxevZqhQ4eGtkdHR/PEE09w8OBBjDEsXbqUkSNHhiscERE5g7DWEGbMmMGUKVMYP348WVlZ9O3bl+nTp7NlyxaSkpKYP38+9957L6NGjcIYw5133hmucERE5AzC2kaTnZ1NdnZ2rXUn9xtkZmaSmZkZzhBERKSRdKuNiIgASggiIlLtvLytp+aWVq/Xe9bv0RwPwZ2t1hqb4mqa1hoXtN7YFFfTNDWumjKzocfPwvZgWjiVlZWxc+fOlg5DROS81LNnT+Lj4+usPy8TQjAYpKKiArvdXuthNxERaZgxBp/PR1xcHFZr3R6D8zIhiIjIuadOZRERAZQQRESkmhKCiIgASggiIlJNCUFERAAlBBERqaaEICIiwHk6dMXXsWLFCp599ll8Ph9Tp07l9ttvb7FY/vCHP/D3v/8dgGHDhvHzn/+cBx98kNzcXGJiYgD44Q9/2OzzREyZMoWioqLQhEXz58/nwIEDLX7cXnvtNZYsWRJaPnToEOPGjcPlcrXIMSsvL2fixIk899xzdO7cmZycHB599FE8Hg+jR48Ozf63fft2Zs+eTXl5OYMGDWLevHlhnwzq1NiWLVvGyy+/jMViIT09nXnz5uFwOPjDH/7AG2+8QUJCAgDf+c53wvrbnhpXQ+d7Q8eyOeLavXs3v/nNb0Lb8vPz6devH88//3yzHq/6yoewn2Mmghw9etSMGDHCHD9+3FRUVJjs7Gyza9euFoll3bp15rbbbjMej8d4vV4zZcoUs3r1apOVlWXy8/NbJCZjjAkGg+baa681Pp8vtK41HbcaO3fuNCNHjjRFRUUtcsw2btxosrKyTJ8+fczBgweNy+Uyw4YNMwcOHDA+n89MmzbN/OMf/zDGGHPzzTebzz//3BhjzIMPPmiWLl3arLHt2bPHjBw50pSVlZlgMGh+/vOfm5deeskYY8zdd99t/vOf/4Q1nobiMsbU+9ud7lg2V1w1CgoKzI033mj27t1rjGm+41Vf+bBixYqwn2MR1WSUk5NDRkYGiYmJxMbGkpmZycqVK1sklpSUFGbNmoXD4cBut3PJJZeQl5dHXl4ec+bMITs7m6eeeopgMNisce3ZsweLxcL06dMZO3YsS5YsaVXHrcbcuXOZMWMG0dHRLXLMli9fzsMPPxyaFnbz5s107dqVLl26YLPZyM7OZuXKlRw+fBi3203//v0BuOWWW8J+7E6NzeFwMHfuXNq0aYPFYqFnz57k5eUBsHXrVhYvXkx2djbz588P6yBup8ZVWVlZ72/X0LFsrrhO9vjjjzNx4kS6desGNN/xqq982LdvX9jPsYhKCAUFBaSkpISWU1NTyc/Pb5FYLrvsstAPuG/fPt5//32uv/56MjIyeOSRR1i+fDkbNmyoNe90cygtLeWaa67h6aef5s9//jOvvvoqeXl5rea4QVVid7vdjB49mqKiohY5ZgsWLGDQoEGh5YbOrVPXp6SkhP3YnRpbp06dGDJkCADFxcUsXbqUG2+8kYqKCnr37s3MmTN56623KC0t5Zlnnmm2uBr67Zr73+mpcdXYt28fn376KVOmTAFo1uNVX/lgsVjCfo5FVEIw9Qzb1NKD4+3atYtp06Yxc+ZMevTowdNPP01ycjIxMTFMnjyZjz76qFnjGTBgAI8//jixsbEkJSUxYcIEnnrqqTqva8nj9uqrr4amW+3SpUuLHzNo+NxqTedcfn4+d9xxB7feeiuDBw8mLi6OxYsX07VrV2w2G9OmTWvWY9fQb9dajtmyZcv47ne/i8PhAGiR43Vy+XDxxRfX2X6uz7GISghpaWkUFhaGlgsKCuqtJjaX3Nxcpk6dyk9/+lO+9a1v8cUXX7Bq1arQdmNM2DsfT7VhwwbWr19fK4ZOnTq1muPm9Xr57LPPuOGGGwBaxTGDhs+tU9cfO3asRY7d7t27mTRpEt/61re47777AMjLy6tVm2ruY9fQb9da/p2uWbOGMWPGhJab+3idWj40xzkWUQlhyJAhrF+/nuLiYlwuF6tXr2bo0KEtEsuRI0e47777ePLJJ7n55puBqhPskUceoaSkBJ/Px7Jly5r9DqOysjIef/xxPB4P5eXlvPXWWzzxxBOt5rh98cUXdOvWjdjYWKB1HDOAfv36sXfvXvbv308gEOC9995j6NChdOrUCafTSW5uLgBvv/12sx+78vJy7rrrLh544AGmTZsWWh8dHc0TTzzBwYMHMcawdOnSZj12Df12DR3L5lRcXIzb7aZLly6hdc15vOorH5rjHIuo207T0tKYMWMGU6ZMwefzMWHCBPr27dsisfzpT3/C4/GwcOHC0LqJEyfy/e9/n0mTJuH3+7npppvIyspq1rhGjBjBpk2bGD9+PMFgkO9+97sMHDiw1Ry3gwcP0r59+9Byr169WvyYATidThYuXMiPfvQjPB4Pw4YNY9SoUQA8+eSTzJ49m4qKCq644opQm3Rzef311yksLOTFF1/kxRdfBOCGG27ggQceYP78+dx77734fD6+8Y1vhJrimsPpfruGjmVzOXToUK3zDCApKanZjldD5UO4zzHNhyAiIkCENRmJiEjDlBBERARQQhARkWpKCCIiAighiIhINSUEkRbyySeftMgtsiINUUIQEREgwh5ME2mKtWvXhuaAiI6OZubMmXz88cfs2rWLwsJCioqK6NWrFwsWLKBNmzbs2rWL+fPnc+LECSwWC9OmTWP8+PFA1cNhL730ElarlYsuuojHHnsMqBrxc8aMGezZswePx8OvfvWregdaE2kWZzdat8iFbe/evSYrK8sUFxcbY6rmX7j22mvNwoULzdChQ82xY8dMIBAwP/nJT8zChQuNz+czN954o1m1apUxpmoOieuvv9785z//Mdu3bzeDBw82eXl5xhhjXnrpJTNnzhzz73//2/Tu3dts3LgxtH7KlCkt84VFjDGqIYjUY926dRQUFDB16tTQOovFwoEDBxg1ahTt2rUDYMKECTzyyCPceuuteDwebrrpJqBqmJSbbrqJf/3rX8THx3PdddfRoUMHgNB7fvLJJ3Tp0oV+/foBVUM5vPHGG833JUVOoYQgUo9gMMg111zDb3/729C6I0eOsGzZMrxeb63XWa3WeiflMcbg9/uJioqqNRyx2+3m8OHDANjt9tD6hoYyFmku6lQWqUdGRgbr1q1j9+7dAHz00UeMHTsWj8fDmjVrKCsrIxgMsnz5ckaMGEH37t2x2+2sXr0aqJp7YNWqVQwZMoTBgwezfv16CgoKgKr5HJ544okW+24iDVENQaQel112GfPnz+cnP/lJaNz7Z599lvXr19OuXTumT5/O8ePHueqqq7jnnnuw2+0888wz/OpXv+L3v/89gUCA++67j4yMDAB+9rOf8b3vfQ+omtHqkUceYd++fS34DUXq0minIk3w+9//nuPHj/O///u/LR2KyDmnJiMREQFUQxARkWqqIYiICKCEICIi1ZQQREQEUEIQEZFqSggiIgIoIYiISLX/D5jhDpwt/4UbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "# # get model accuracy # #\n",
    "##########################\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "######################\n",
    "# # get model loss # #\n",
    "######################\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d2413",
   "metadata": {},
   "source": [
    "#### SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1247bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # save model # #\n",
    "##################\n",
    "model.model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799eac",
   "metadata": {},
   "source": [
    "# LIVE TESTING\n",
    "> Live test with new dataset to check if model function as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0074460",
   "metadata": {},
   "source": [
    "#### LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1da540d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # load model # #\n",
    "##################\n",
    "\n",
    "# model = create_model()\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f0646",
   "metadata": {},
   "source": [
    "#### LOAD DATA\n",
    "- Import new dataset to verify the model is able to predict accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29bff51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>D|0</th>\n",
       "      <th>I|0+1</th>\n",
       "      <th>PF|0+1</th>\n",
       "      <th>RF|0+1</th>\n",
       "      <th>DT|0+1</th>\n",
       "      <th>D|1</th>\n",
       "      <th>I|1+2</th>\n",
       "      <th>PF|1+2</th>\n",
       "      <th>...</th>\n",
       "      <th>T4-RF-VAR.1</th>\n",
       "      <th>T4-G-VAR.1</th>\n",
       "      <th>T4-I-SD.1</th>\n",
       "      <th>T4-PF-SD.1</th>\n",
       "      <th>T4-RF-SD.1</th>\n",
       "      <th>T4-G-SD.1</th>\n",
       "      <th>T5_I|0+4.1</th>\n",
       "      <th>T5_PF|0+4.1</th>\n",
       "      <th>T5_RF|0+4.1</th>\n",
       "      <th>T5_G|0+4.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adhy</td>\n",
       "      <td>quail</td>\n",
       "      <td>0.119654</td>\n",
       "      <td>-0.024004</td>\n",
       "      <td>0.09565</td>\n",
       "      <td>0.080376</td>\n",
       "      <td>0.20003</td>\n",
       "      <td>0.10438</td>\n",
       "      <td>0.304264</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080180</td>\n",
       "      <td>0.097463</td>\n",
       "      <td>0.271303</td>\n",
       "      <td>0.300333</td>\n",
       "      <td>0.283161</td>\n",
       "      <td>0.312191</td>\n",
       "      <td>0.616362</td>\n",
       "      <td>0.769361</td>\n",
       "      <td>0.736033</td>\n",
       "      <td>0.889032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adhy</td>\n",
       "      <td>quail</td>\n",
       "      <td>0.119654</td>\n",
       "      <td>-0.024004</td>\n",
       "      <td>0.09565</td>\n",
       "      <td>0.080376</td>\n",
       "      <td>0.20003</td>\n",
       "      <td>0.10438</td>\n",
       "      <td>0.304264</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.034878</td>\n",
       "      <td>0.034673</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.344067</td>\n",
       "      <td>0.456247</td>\n",
       "      <td>0.416209</td>\n",
       "      <td>0.528389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adhy</td>\n",
       "      <td>quail</td>\n",
       "      <td>0.119654</td>\n",
       "      <td>-0.024004</td>\n",
       "      <td>0.09565</td>\n",
       "      <td>0.080376</td>\n",
       "      <td>0.20003</td>\n",
       "      <td>0.10438</td>\n",
       "      <td>0.304264</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.113785</td>\n",
       "      <td>0.096630</td>\n",
       "      <td>0.096813</td>\n",
       "      <td>0.079658</td>\n",
       "      <td>1.008275</td>\n",
       "      <td>1.128276</td>\n",
       "      <td>1.128039</td>\n",
       "      <td>1.248040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adhy</td>\n",
       "      <td>quail</td>\n",
       "      <td>0.119654</td>\n",
       "      <td>-0.024004</td>\n",
       "      <td>0.09565</td>\n",
       "      <td>0.080376</td>\n",
       "      <td>0.20003</td>\n",
       "      <td>0.10438</td>\n",
       "      <td>0.304264</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>0.061637</td>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>0.100657</td>\n",
       "      <td>0.375933</td>\n",
       "      <td>0.487393</td>\n",
       "      <td>0.439950</td>\n",
       "      <td>0.551410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adhy</td>\n",
       "      <td>quail</td>\n",
       "      <td>0.119654</td>\n",
       "      <td>-0.024004</td>\n",
       "      <td>0.09565</td>\n",
       "      <td>0.080376</td>\n",
       "      <td>0.20003</td>\n",
       "      <td>0.10438</td>\n",
       "      <td>0.304264</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.050886</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.423579</td>\n",
       "      <td>0.575900</td>\n",
       "      <td>0.535566</td>\n",
       "      <td>0.687887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Sequence       D|0     I|0+1   PF|0+1    RF|0+1   DT|0+1      D|1  \\\n",
       "0    adhy    quail  0.119654 -0.024004  0.09565  0.080376  0.20003  0.10438   \n",
       "1    adhy    quail  0.119654 -0.024004  0.09565  0.080376  0.20003  0.10438   \n",
       "2    adhy    quail  0.119654 -0.024004  0.09565  0.080376  0.20003  0.10438   \n",
       "3    adhy    quail  0.119654 -0.024004  0.09565  0.080376  0.20003  0.10438   \n",
       "4    adhy    quail  0.119654 -0.024004  0.09565  0.080376  0.20003  0.10438   \n",
       "\n",
       "      I|1+2    PF|1+2  ...  T4-RF-VAR.1  T4-G-VAR.1  T4-I-SD.1  T4-PF-SD.1  \\\n",
       "0  0.304264  0.408644  ...     0.080180    0.097463   0.271303    0.300333   \n",
       "1  0.304264  0.408644  ...     0.000036    0.000034   0.034878    0.034673   \n",
       "2  0.304264  0.408644  ...     0.009373    0.006345   0.113785    0.096630   \n",
       "3  0.304264  0.408644  ...     0.012563    0.010132   0.061637    0.050211   \n",
       "4  0.304264  0.408644  ...     0.009327    0.004563   0.079918    0.050886   \n",
       "\n",
       "   T4-RF-SD.1  T4-G-SD.1  T5_I|0+4.1  T5_PF|0+4.1  T5_RF|0+4.1  T5_G|0+4.1  \n",
       "0    0.283161   0.312191    0.616362     0.769361     0.736033    0.889032  \n",
       "1    0.005993   0.005788    0.344067     0.456247     0.416209    0.528389  \n",
       "2    0.096813   0.079658    1.008275     1.128276     1.128039    1.248040  \n",
       "3    0.112083   0.100657    0.375933     0.487393     0.439950    0.551410  \n",
       "4    0.096579   0.067547    0.423579     0.575900     0.535566    0.687887  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import unseen data\n",
    "pred_df = pd.read_csv(ACTUAL_DATASET_PATH)\n",
    "pred_df.head()\n",
    "# pred_df = df_drop(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "837b9992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################\n",
    "# # check for class validity # #\n",
    "################################\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"Subject\", data=pred_df).set_title(\"Class Validity\")\n",
    "\n",
    "# remove missing values if available\n",
    "pred_df = pred_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b061d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adhy', 'andy', 'bryce', 'chris', 'cy', 'hr', 'jc', 'ys']\n"
     ]
    }
   ],
   "source": [
    "pred_dataset = pred_df.values\n",
    "results = pred_dataset[:,CLASSES_COL_NUM]\n",
    "\n",
    "# # divide data into features X\n",
    "# pred_row = pred_dataset[:,3:].astype(float)\n",
    "\n",
    "########################\n",
    "# # predict all rows # #\n",
    "########################\n",
    "pred_row=pred_df.iloc[:,FEATURES_COL_NUM:]\n",
    "\n",
    "#################################\n",
    "# # predict more than one row # #\n",
    "#################################\n",
    "\n",
    "# pred_row=pred_df.iloc[46:54,FEATURES_COL_NUM:]\n",
    "# print(pred_row)\n",
    "\n",
    "############################\n",
    "# # predict a single row # #\n",
    "############################\n",
    "\n",
    "# pred_row=pred_df.iloc[11:12,FEATURES_COL_NUM:]\n",
    "\n",
    "##################\n",
    "# # shape data # #\n",
    "##################\n",
    "pred_row = pred_row.values.tolist()\n",
    "pred_arr = np.asarray(pred_row, dtype=np.float32)\n",
    "pred_arr = np.reshape(pred_arr, (pred_arr.shape[0], TIMESTEPS, pred_arr.shape[1]))\n",
    "\n",
    "Y = CLASS_LIST\n",
    "print(Y)\n",
    "Y = np.asarray(Y)\n",
    "Y = Y.reshape(-1, 1)\n",
    "lb = LabelBinarizer().fit(Y)\n",
    "Y = lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad543869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Results Prediction    Accuracy\n",
      "0      adhy      bryce  0.61084884\n",
      "1      adhy      chris   0.9999734\n",
      "2      adhy         ys   0.9999906\n",
      "3      adhy      chris   0.9999926\n",
      "4      adhy      chris   0.9999932\n",
      "5      adhy      chris    0.999987\n",
      "6      adhy      chris  0.99997306\n",
      "7      adhy      chris   0.9999951\n",
      "8      adhy      chris     0.99998\n",
      "9      adhy      chris  0.99184287\n",
      "10     adhy         hr   0.7592791\n",
      "11     adhy         ys   0.9271811\n",
      "12     adhy         hr   0.9989794\n",
      "13     adhy         hr  0.89189625\n",
      "14     adhy         hr  0.83677214\n",
      "15     adhy      chris  0.85743225\n",
      "16     adhy         hr  0.62696326\n",
      "17     adhy         hr  0.96320355\n",
      "18     adhy      chris   0.9999957\n",
      "19     adhy         hr  0.90124655\n",
      "20     adhy         ys   0.9999671\n",
      "21     adhy         hr   0.9999919\n",
      "22     adhy      chris  0.99999595\n",
      "23     adhy      chris  0.99459535\n",
      "24     adhy      chris  0.73545396\n",
      "25     adhy      chris   0.9999938\n",
      "26     adhy         hr  0.50115836\n",
      "27     adhy         ys   0.9999913\n",
      "28     adhy         hr   0.8073974\n",
      "29     adhy         ys   0.9611062\n",
      "30     adhy         ys  0.99989533\n",
      "31     adhy         ys  0.99363023\n",
      "32     adhy         ys   0.9795878\n",
      "33     adhy         ys    0.998855\n",
      "34     adhy         ys  0.84285235\n",
      "35     adhy         ys   0.9996057\n",
      "36     adhy      chris  0.99999344\n",
      "37     adhy         hr   0.9998691\n",
      "38     adhy      chris   0.7710501\n",
      "39     adhy         ys   0.9998869\n",
      "40     adhy      chris   0.9999747\n",
      "41     adhy      chris  0.98999995\n",
      "42     adhy       andy  0.90095043\n",
      "43     adhy      chris  0.99996984\n",
      "44     adhy         hr   0.9836646\n",
      "45     adhy      chris   0.9999939\n",
      "46     adhy         hr   0.9339478\n",
      "47     adhy      chris  0.99998987\n",
      "48     adhy         ys  0.99999475\n",
      "49     adhy      chris    0.994779\n",
      "50     adhy      chris  0.99999094\n",
      "51     adhy      chris   0.9999553\n",
      "52     adhy      chris   0.9999957\n",
      "53     adhy      chris   0.9999931\n",
      "54     adhy      chris  0.99998915\n",
      "55     adhy         hr  0.99789315\n",
      "56     adhy      chris    0.920142\n",
      "57     adhy         ys  0.99997437\n",
      "58     adhy         hr  0.91055506\n",
      "59     adhy      chris  0.99998915\n",
      "60     adhy      chris   0.9997992\n",
      "61     adhy      chris  0.99998415\n",
      "62     adhy      chris  0.93888354\n",
      "63     adhy      chris  0.96208197\n",
      "64     adhy         hr   0.9996537\n",
      "65     adhy       adhy   0.5871004\n",
      "66     adhy         ys  0.99991894\n",
      "67     adhy       adhy   0.6830654\n",
      "68     adhy      chris   0.9989479\n",
      "69     adhy      chris   0.7888018\n",
      "70     adhy       adhy   0.9999434\n",
      "71     adhy      chris   0.9734072\n",
      "72     adhy      chris   0.9999932\n",
      "73     adhy         hr   0.8960297\n",
      "74     adhy      chris   0.6529088\n",
      "75     adhy         ys  0.99995816\n",
      "76     adhy         hr   0.9999435\n",
      "77     adhy      chris  0.99999666\n",
      "78     adhy       adhy   0.6529575\n",
      "79     adhy       andy   0.9983583\n",
      "80     adhy         hr   0.6232084\n",
      "81     adhy      chris  0.99999106\n",
      "82     adhy         hr   0.9999343\n",
      "83     adhy         cy   0.9993507\n",
      "84     adhy         ys   0.9998466\n",
      "85     adhy         hr  0.99999356\n",
      "86     adhy      chris   0.9999865\n",
      "87     adhy         hr  0.99932957\n",
      "88     adhy       andy  0.97588104\n",
      "89     adhy      chris   0.9999045\n",
      "90     andy      chris  0.82496566\n",
      "91     andy       andy   0.7314308\n",
      "92     andy      chris    0.515164\n",
      "93     andy       andy   0.9826645\n",
      "94     andy       andy   0.9997067\n",
      "95     andy      chris   0.9999566\n",
      "96     andy       adhy   0.9882406\n",
      "97     andy         cy  0.99979705\n",
      "98     andy         cy   0.9968838\n",
      "99     andy         cy   0.8456912\n",
      "100    andy       andy   0.9729733\n",
      "101    andy      chris   0.7600188\n",
      "102    andy       andy   0.9999212\n",
      "103    andy       andy   0.9999591\n",
      "104    andy      chris  0.99990666\n",
      "105    andy       adhy  0.99974424\n",
      "106    andy       andy   0.9999238\n",
      "107    andy      bryce  0.81367296\n",
      "108    andy       andy   0.9408983\n",
      "109    andy       andy   0.5619393\n",
      "110    andy       andy  0.99986124\n",
      "111    andy       andy  0.99994636\n",
      "112    andy       andy   0.9999566\n",
      "113    andy      chris  0.99961543\n",
      "114    andy       adhy   0.9999807\n",
      "115    andy       andy  0.99994016\n",
      "116    andy       andy   0.9092334\n",
      "117    andy         cy  0.95807666\n",
      "118    andy       andy   0.9975157\n",
      "119    andy       andy   0.9999348\n",
      "120    andy       andy   0.9999045\n",
      "121    andy       andy  0.99997306\n",
      "122    andy      chris  0.98013043\n",
      "123    andy       adhy   0.9999864\n",
      "124    andy       andy  0.99986994\n",
      "125    andy         cy  0.65195185\n",
      "126    andy       adhy  0.85729504\n",
      "127    andy       andy  0.99991846\n",
      "128    andy       andy   0.9999608\n",
      "129    andy       andy   0.9999471\n",
      "130    andy       andy   0.9999695\n",
      "131    andy      chris   0.9998828\n",
      "132    andy       adhy  0.99978155\n",
      "133    andy       andy   0.9998896\n",
      "134    andy         cy  0.99990773\n",
      "135    andy       andy   0.9600872\n",
      "136    andy       andy   0.9999236\n",
      "137    andy       andy  0.99995995\n",
      "138    andy       andy   0.9999442\n",
      "139    andy       andy   0.9999646\n",
      "140    andy       andy  0.93170303\n",
      "141    andy       adhy   0.5846357\n",
      "142    andy       andy   0.9998758\n",
      "143    andy       andy   0.7777417\n",
      "144    andy       andy  0.53078705\n",
      "145    andy       andy  0.99237025\n",
      "146    andy       andy   0.9999341\n",
      "147    andy      chris    0.970348\n",
      "148    andy       andy    0.999933\n",
      "149    andy       andy   0.9999496\n",
      "150    andy       adhy   0.9999927\n",
      "151    andy       andy   0.9998758\n",
      "152    andy      bryce   0.9999809\n",
      "153    andy       adhy   0.9999958\n",
      "154    andy       adhy   0.9999809\n",
      "155    andy         hr     0.99999\n",
      "156    andy       adhy   0.9999695\n",
      "157    andy       adhy  0.83619475\n",
      "158    andy       adhy   0.9018851\n",
      "159    andy       adhy  0.71871036\n",
      "160    andy       adhy  0.99870944\n",
      "161    andy       adhy  0.42286134\n",
      "162    andy         cy  0.99999547\n",
      "163    andy         cy   0.4237288\n",
      "164    andy       andy   0.9998746\n",
      "165    andy       andy  0.93254805\n",
      "166    andy       andy   0.9999187\n",
      "167    andy       andy  0.99994075\n",
      "168    andy         cy  0.99824584\n",
      "169    andy       adhy  0.99978775\n",
      "170    andy      bryce   0.9822046\n",
      "171    andy         cy   0.9999938\n",
      "172    andy         cy  0.70580083\n",
      "173    andy       andy   0.6073797\n",
      "174    andy         cy    0.987926\n",
      "175    andy       andy  0.50127375\n",
      "176    andy       andy   0.6758177\n",
      "177    andy      bryce   0.9646287\n",
      "178    andy       adhy   0.5405417\n",
      "179    andy         cy   0.9997938\n",
      "180   bryce      chris  0.95402694\n",
      "181   bryce       adhy   0.9401168\n",
      "182   bryce         hr  0.90260947\n",
      "183   bryce      bryce   0.7266416\n",
      "184   bryce      bryce  0.61641395\n",
      "185   bryce      chris  0.99977154\n",
      "186   bryce       adhy  0.84143203\n",
      "187   bryce         ys  0.38268423\n",
      "188   bryce      chris  0.99987686\n",
      "189   bryce      chris   0.9999944\n",
      "190   bryce      bryce   0.9996555\n",
      "191   bryce         hr   0.9994368\n",
      "192   bryce      bryce  0.99991417\n",
      "193   bryce      bryce   0.9998072\n",
      "194   bryce      bryce  0.99998486\n",
      "195   bryce      bryce   0.9999627\n",
      "196   bryce      bryce  0.86624146\n",
      "197   bryce         hr  0.89270747\n",
      "198   bryce       adhy   0.7019277\n",
      "199   bryce      bryce   0.6177299\n",
      "200   bryce         hr   0.7013405\n",
      "201   bryce      bryce   0.9928268\n",
      "202   bryce      bryce   0.9667477\n",
      "203   bryce      bryce  0.99998057\n",
      "204   bryce      bryce  0.95410895\n",
      "205   bryce      bryce  0.70788634\n",
      "206   bryce      bryce   0.6689626\n",
      "207   bryce         jc  0.95291585\n",
      "208   bryce         hr  0.99999475\n",
      "209   bryce       adhy  0.91469604\n",
      "210   bryce         ys   0.9113976\n",
      "211   bryce         hr   0.9995134\n",
      "212   bryce         hr   0.4643008\n",
      "213   bryce       adhy  0.43291685\n",
      "214   bryce         hr   0.9996847\n",
      "215   bryce         hr  0.99997723\n",
      "216   bryce      chris  0.99999547\n",
      "217   bryce      bryce    0.999992\n",
      "218   bryce      bryce   0.9999927\n",
      "219   bryce         hr  0.99028814\n",
      "220   bryce      bryce   0.9999933\n",
      "221   bryce      bryce  0.99999404\n",
      "222   bryce      bryce  0.99998665\n",
      "223   bryce      bryce  0.99997973\n",
      "224   bryce      bryce    0.999741\n",
      "225   bryce      chris   0.9999585\n",
      "226   bryce         hr  0.99994504\n",
      "227   bryce      bryce   0.9815761\n",
      "228   bryce         hr  0.99999344\n",
      "229   bryce      bryce   0.9729028\n",
      "230   bryce      bryce   0.9999907\n",
      "231   bryce      bryce  0.99998903\n",
      "232   bryce         hr   0.7796635\n",
      "233   bryce         hr  0.98110217\n",
      "234   bryce      chris  0.93486136\n",
      "235   bryce      bryce  0.99954706\n",
      "236   bryce      bryce   0.9737221\n",
      "237   bryce         hr  0.99527055\n",
      "238   bryce      bryce  0.99997616\n",
      "239   bryce      bryce   0.9999585\n",
      "240   bryce      bryce   0.9999788\n",
      "241   bryce      bryce   0.9997143\n",
      "242   bryce      bryce  0.65251404\n",
      "243   bryce       adhy  0.82441175\n",
      "244   bryce         hr  0.99259794\n",
      "245   bryce       adhy   0.9999887\n",
      "246   bryce         hr   0.9992487\n",
      "247   bryce       adhy    0.642475\n",
      "248   bryce       adhy   0.7199179\n",
      "249   bryce       adhy    0.533592\n",
      "250   bryce      bryce   0.9875064\n",
      "251   bryce      bryce  0.99965656\n",
      "252   bryce         ys   0.9820374\n",
      "253   bryce         hr   0.9999937\n",
      "254   bryce      bryce   0.8039787\n",
      "255   bryce         hr   0.7465403\n",
      "256   bryce      bryce  0.84300977\n",
      "257   bryce      bryce   0.9895092\n",
      "258   bryce      bryce   0.9999825\n",
      "259   bryce      bryce   0.9999831\n",
      "260   bryce         hr  0.99979466\n",
      "261   bryce      chris   0.9742975\n",
      "262   bryce         hr   0.9011171\n",
      "263   bryce      bryce   0.8969357\n",
      "264   bryce         hr    0.999997\n",
      "265   bryce      bryce  0.99946123\n",
      "266   bryce         hr  0.88822657\n",
      "267   bryce      bryce   0.9889782\n",
      "268   bryce      bryce  0.99995244\n",
      "269   bryce         hr  0.99282277\n",
      "270   chris      chris   0.9999945\n",
      "271   chris      chris  0.99775344\n",
      "272   chris         hr   0.6640015\n",
      "273   chris      chris   0.8139933\n",
      "274   chris      bryce  0.98876333\n",
      "275   chris      chris  0.98779815\n",
      "276   chris       andy  0.99964345\n",
      "277   chris      bryce   0.9670778\n",
      "278   chris      bryce  0.99996424\n",
      "279   chris       adhy    0.490547\n",
      "280   chris      chris   0.9999943\n",
      "281   chris      chris  0.80368817\n",
      "282   chris      chris   0.6392929\n",
      "283   chris      chris   0.9957955\n",
      "284   chris      chris   0.9402437\n",
      "285   chris       andy   0.8023553\n",
      "286   chris      chris   0.7235614\n",
      "287   chris      bryce  0.99712545\n",
      "288   chris       adhy   0.9330486\n",
      "289   chris      chris    0.999992\n",
      "290   chris       adhy   0.9975636\n",
      "291   chris      chris   0.9999875\n",
      "292   chris       adhy   0.7138002\n",
      "293   chris      chris    0.760144\n",
      "294   chris      chris   0.9953518\n",
      "295   chris         hr  0.99461573\n",
      "296   chris      bryce    0.999984\n",
      "297   chris         cy  0.99945444\n",
      "298   chris      chris   0.9999883\n",
      "299   chris      chris   0.9999875\n",
      "300   chris      chris  0.99996865\n",
      "301   chris         hr  0.98179287\n",
      "302   chris      chris  0.99996936\n",
      "303   chris      chris   0.7115628\n",
      "304   chris         hr  0.98505545\n",
      "305   chris      bryce   0.9998847\n",
      "306   chris      chris  0.76140255\n",
      "307   chris      chris  0.99998677\n",
      "308   chris      chris   0.9999926\n",
      "309   chris      chris    0.999987\n",
      "310   chris      chris  0.99785715\n",
      "311   chris      chris   0.9513073\n",
      "312   chris         cy   0.6042915\n",
      "313   chris      bryce   0.7255625\n",
      "314   chris      bryce   0.9999713\n",
      "315   chris      bryce   0.8630595\n",
      "316   chris      chris  0.99999547\n",
      "317   chris      chris  0.99998987\n",
      "318   chris         hr  0.86020094\n",
      "319   chris      bryce  0.83672947\n",
      "320   chris      bryce   0.9880229\n",
      "321   chris      chris  0.49571317\n",
      "322   chris      bryce  0.64639723\n",
      "323   chris      bryce   0.9999939\n",
      "324   chris         cy  0.86086255\n",
      "325   chris      chris    0.999972\n",
      "326   chris      chris   0.9364607\n",
      "327   chris       adhy   0.9999765\n",
      "328   chris      bryce  0.98833466\n",
      "329   chris      bryce  0.99453956\n",
      "330   chris       andy  0.93720853\n",
      "331   chris      bryce  0.57656085\n",
      "332   chris      bryce   0.9999877\n",
      "333   chris         cy  0.83722645\n",
      "334   chris       andy  0.99996173\n",
      "335   chris      chris  0.99498004\n",
      "336   chris       adhy  0.65101045\n",
      "337   chris       andy   0.9997576\n",
      "338   chris       andy   0.9999572\n",
      "339   chris       andy   0.9996301\n",
      "340   chris       andy    0.939964\n",
      "341   chris       andy   0.9998715\n",
      "342   chris         cy  0.99511164\n",
      "343   chris      chris   0.8243852\n",
      "344   chris      chris  0.96958995\n",
      "345   chris         hr  0.99999154\n",
      "346   chris      chris  0.97453296\n",
      "347   chris         hr  0.99998987\n",
      "348   chris      bryce   0.9792347\n",
      "349   chris         cy  0.93259543\n",
      "350   chris      bryce  0.99994123\n",
      "351   chris         cy   0.9788836\n",
      "352   chris      bryce  0.73698604\n",
      "353   chris      bryce     0.89005\n",
      "354   chris      chris  0.97085965\n",
      "355   chris      chris   0.9888254\n",
      "356   chris      bryce   0.9998714\n",
      "357   chris      chris    0.999683\n",
      "358   chris      bryce   0.7154441\n",
      "359   chris      bryce  0.99984396\n",
      "360      cy      bryce     0.88021\n",
      "361      cy         cy  0.99971765\n",
      "362      cy      bryce  0.99968004\n",
      "363      cy      bryce  0.99973994\n",
      "364      cy      bryce   0.6493292\n",
      "365      cy      bryce   0.9897239\n",
      "366      cy      bryce  0.92733765\n",
      "367      cy      bryce  0.67055416\n",
      "368      cy      bryce  0.78237015\n",
      "369      cy         cy   0.9999895\n",
      "370      cy         ys   0.8692527\n",
      "371      cy         jc   0.9802714\n",
      "372      cy         hr  0.99999726\n",
      "373      cy         ys    0.977111\n",
      "374      cy       adhy    0.985365\n",
      "375      cy         jc  0.70138603\n",
      "376      cy         hr    0.887441\n",
      "377      cy         ys   0.9999819\n",
      "378      cy         cy   0.9999497\n",
      "379      cy      chris   0.9565493\n",
      "380      cy      chris   0.9939433\n",
      "381      cy      chris  0.99993753\n",
      "382      cy      chris   0.9829579\n",
      "383      cy      chris  0.99997616\n",
      "384      cy      bryce  0.99969137\n",
      "385      cy      chris   0.6772738\n",
      "386      cy         cy   0.8964112\n",
      "387      cy         cy  0.99998987\n",
      "388      cy         jc   0.9798835\n",
      "389      cy         cy  0.57451314\n",
      "390      cy         hr  0.99999475\n",
      "391      cy         ys  0.70357054\n",
      "392      cy      chris  0.91886216\n",
      "393      cy      bryce  0.92606544\n",
      "394      cy         jc   0.9939221\n",
      "395      cy         cy    0.999992\n",
      "396      cy         cy  0.99996257\n",
      "397      cy         ys   0.8193278\n",
      "398      cy      chris   0.9612075\n",
      "399      cy         hr   0.8870899\n",
      "400      cy      bryce   0.7546305\n",
      "401      cy      chris  0.99679035\n",
      "402      cy      bryce   0.8614862\n",
      "403      cy         hr  0.99911445\n",
      "404      cy         cy   0.9999969\n",
      "405      cy         cy   0.9999659\n",
      "406      cy       adhy  0.85258913\n",
      "407      cy         cy  0.99915946\n",
      "408      cy         cy   0.9897809\n",
      "409      cy         cy  0.99153274\n",
      "410      cy       adhy   0.9999087\n",
      "411      cy      bryce   0.9999963\n",
      "412      cy         cy   0.5401261\n",
      "413      cy         cy   0.9999726\n",
      "414      cy         cy   0.9997819\n",
      "415      cy      bryce  0.99935883\n",
      "416      cy      chris  0.99901783\n",
      "417      cy       adhy     0.73686\n",
      "418      cy         hr   0.9997595\n",
      "419      cy      bryce   0.9804457\n",
      "420      cy      bryce   0.9999912\n",
      "421      cy         cy   0.9953381\n",
      "422      cy         cy   0.9998288\n",
      "423      cy         cy  0.99999475\n",
      "424      cy         jc  0.99814343\n",
      "425      cy         cy   0.9857164\n",
      "426      cy         jc   0.9999343\n",
      "427      cy         hr    0.999871\n",
      "428      cy      bryce    0.977437\n",
      "429      cy      bryce   0.9907794\n",
      "430      cy         jc   0.9994624\n",
      "431      cy         ys  0.99959725\n",
      "432      cy         cy   0.9999887\n",
      "433      cy         jc   0.9981602\n",
      "434      cy         cy   0.9997938\n",
      "435      cy         jc   0.8488711\n",
      "436      cy         hr  0.99998236\n",
      "437      cy      bryce   0.8026241\n",
      "438      cy      chris  0.54962826\n",
      "439      cy         jc   0.9276391\n",
      "440      cy         cy  0.99999535\n",
      "441      cy         cy   0.9998223\n",
      "442      cy         cy    0.960728\n",
      "443      cy         cy  0.99813324\n",
      "444      cy         cy  0.99999475\n",
      "445      cy         cy    0.999997\n",
      "446      cy      bryce  0.80223405\n",
      "447      cy         cy   0.9999844\n",
      "448      cy      bryce   0.9153398\n",
      "449      cy         cy  0.99999714\n",
      "450      hr         ys  0.90110826\n",
      "451      hr         jc   0.9999888\n",
      "452      hr         hr   0.9999808\n",
      "453      hr         jc    0.958852\n",
      "454      hr         hr   0.9999943\n",
      "455      hr         ys   0.8464537\n",
      "456      hr         hr   0.8898397\n",
      "457      hr         hr   0.9995479\n",
      "458      hr         hr   0.7496997\n",
      "459      hr         ys   0.5897796\n",
      "460      hr      bryce   0.9999443\n",
      "461      hr         hr   0.9572144\n",
      "462      hr      bryce  0.99995863\n",
      "463      hr         hr   0.9999527\n",
      "464      hr      chris   0.9994518\n",
      "465      hr       adhy    0.769027\n",
      "466      hr         hr   0.8948333\n",
      "467      hr      chris   0.9986046\n",
      "468      hr         jc  0.99992394\n",
      "469      hr         hr   0.8772571\n",
      "470      hr         hr  0.99992406\n",
      "471      hr      bryce   0.9999939\n",
      "472      hr         hr  0.99999785\n",
      "473      hr         hr  0.61621773\n",
      "474      hr         hr  0.99999416\n",
      "475      hr         hr  0.99998665\n",
      "476      hr         hr  0.99965453\n",
      "477      hr       adhy   0.9272433\n",
      "478      hr      chris   0.9999747\n",
      "479      hr         hr  0.99985147\n",
      "480      hr      chris  0.96553427\n",
      "481      hr         hr  0.99999714\n",
      "482      hr      chris  0.99836224\n",
      "483      hr         hr  0.99999285\n",
      "484      hr         hr   0.9995907\n",
      "485      hr         hr  0.99955326\n",
      "486      hr         jc   0.8057489\n",
      "487      hr      bryce   0.9999697\n",
      "488      hr      bryce   0.9999881\n",
      "489      hr      bryce  0.98410714\n",
      "490      hr      bryce   0.9996493\n",
      "491      hr      bryce  0.99996316\n",
      "492      hr       adhy   0.9999784\n",
      "493      hr      bryce    0.999967\n",
      "494      hr      bryce  0.99943763\n",
      "495      hr         hr  0.99968016\n",
      "496      hr         hr  0.90891844\n",
      "497      hr         hr   0.9999553\n",
      "498      hr         hr    0.999995\n",
      "499      hr      bryce  0.99976546\n",
      "500      hr         hr  0.68677026\n",
      "501      hr         hr   0.9999962\n",
      "502      hr         hr    0.994998\n",
      "503      hr         hr   0.9985661\n",
      "504      hr         ys  0.81315863\n",
      "505      hr      chris  0.99999106\n",
      "506      hr         hr   0.8273122\n",
      "507      hr      chris  0.84202975\n",
      "508      hr      bryce   0.9999467\n",
      "509      hr         hr   0.9999796\n",
      "510      hr       adhy   0.9998411\n",
      "511      hr      bryce   0.7370977\n",
      "512      hr      chris  0.99994564\n",
      "513      hr         hr   0.6696001\n",
      "514      hr         hr  0.97165763\n",
      "515      hr         hr  0.99998844\n",
      "516      hr         hr   0.9999858\n",
      "517      hr         hr   0.8129759\n",
      "518      hr         hr   0.9999958\n",
      "519      hr         hr  0.99996257\n",
      "520      hr         hr   0.9999951\n",
      "521      hr         hr  0.97939026\n",
      "522      hr         ys   0.9965153\n",
      "523      hr      chris  0.96814895\n",
      "524      hr         hr  0.95771724\n",
      "525      hr         hr  0.99957424\n",
      "526      hr      bryce   0.9999887\n",
      "527      hr         hr   0.9999937\n",
      "528      hr      chris  0.71609867\n",
      "529      hr         hr   0.9999924\n",
      "530      hr         hr    0.998803\n",
      "531      hr         ys   0.8021139\n",
      "532      hr      chris  0.99846965\n",
      "533      hr         hr    0.999798\n",
      "534      hr         hr  0.99999714\n",
      "535      hr      bryce   0.5625676\n",
      "536      hr         hr   0.9999974\n",
      "537      hr      chris   0.6353608\n",
      "538      hr         hr  0.62258875\n",
      "539      hr         hr  0.98475665\n",
      "540      jc         ys  0.99998975\n",
      "541      jc         ys   0.9999882\n",
      "542      jc         ys  0.99995637\n",
      "543      jc         ys   0.9999982\n",
      "544      jc         ys    0.987305\n",
      "545      jc         ys   0.9999832\n",
      "546      jc         ys   0.9999739\n",
      "547      jc         ys  0.99998474\n",
      "548      jc         ys  0.99999666\n",
      "549      jc         ys   0.9999846\n",
      "550      jc         jc   0.9999937\n",
      "551      jc         jc   0.9999932\n",
      "552      jc         jc   0.9998306\n",
      "553      jc         jc  0.99999607\n",
      "554      jc         jc  0.99999356\n",
      "555      jc         jc   0.9999889\n",
      "556      jc         jc   0.9999943\n",
      "557      jc         jc   0.9999516\n",
      "558      jc         ys  0.99999595\n",
      "559      jc         jc   0.9999919\n",
      "560      jc         jc   0.9999919\n",
      "561      jc         jc   0.9987136\n",
      "562      jc         jc  0.99999523\n",
      "563      jc         jc  0.99999356\n",
      "564      jc         jc   0.9999893\n",
      "565      jc         jc   0.9999937\n",
      "566      jc         jc   0.9930587\n",
      "567      jc         ys   0.9999924\n",
      "568      jc         jc  0.99999595\n",
      "569      jc         jc   0.9999956\n",
      "570      jc         jc   0.9999428\n",
      "571      jc         jc   0.9999968\n",
      "572      jc         jc   0.9999963\n",
      "573      jc         jc  0.99999106\n",
      "574      jc         jc   0.9999962\n",
      "575      jc         jc  0.99998796\n",
      "576      jc         ys  0.99999774\n",
      "577      jc         jc   0.9999577\n",
      "578      jc         jc  0.99998534\n",
      "579      jc         jc   0.9999933\n",
      "580      jc         jc    0.999995\n",
      "581      jc         jc   0.9999913\n",
      "582      jc         jc  0.99986124\n",
      "583      jc         jc   0.9999428\n",
      "584      jc         jc   0.9368057\n",
      "585      jc         ys    0.999949\n",
      "586      jc         jc   0.9999944\n",
      "587      jc         jc   0.9999957\n",
      "588      jc         jc  0.99999654\n",
      "589      jc         jc   0.9999902\n",
      "590      jc         jc  0.99999595\n",
      "591      jc         jc  0.99999166\n",
      "592      jc         jc  0.99999547\n",
      "593      jc         jc  0.99929214\n",
      "594      jc         ys  0.99997413\n",
      "595      jc         jc   0.9999924\n",
      "596      jc         jc  0.99999416\n",
      "597      jc         jc  0.99999523\n",
      "598      jc         jc   0.9999447\n",
      "599      jc         jc  0.99999523\n",
      "600      jc         jc   0.9999907\n",
      "601      jc         jc  0.99999475\n",
      "602      jc         jc  0.77282625\n",
      "603      jc         ys   0.9998766\n",
      "604      jc         jc   0.9999862\n",
      "605      jc         jc   0.9997986\n",
      "606      jc         jc   0.9999428\n",
      "607      jc         jc   0.9652805\n",
      "608      jc         jc   0.9999902\n",
      "609      jc         jc   0.9999747\n",
      "610      jc         jc  0.99992895\n",
      "611      jc         jc  0.98645765\n",
      "612      jc         ys    0.999995\n",
      "613      jc         jc   0.9999887\n",
      "614      jc         jc  0.99998856\n",
      "615      jc         jc   0.9999877\n",
      "616      jc         jc   0.9240511\n",
      "617      jc         jc   0.9999957\n",
      "618      jc         jc   0.9999927\n",
      "619      jc         jc   0.9999862\n",
      "620      jc         jc   0.9926548\n",
      "621      jc         ys   0.9999888\n",
      "622      jc         jc   0.9998841\n",
      "623      jc         jc  0.99976534\n",
      "624      jc         jc   0.9999846\n",
      "625      jc         jc   0.9873746\n",
      "626      jc         jc  0.99999464\n",
      "627      jc         jc   0.9999925\n",
      "628      jc         jc   0.9999273\n",
      "629      jc         jc   0.9999083\n",
      "630      ys         ys  0.99999344\n",
      "631      ys         ys   0.9999919\n",
      "632      ys         ys   0.8886182\n",
      "633      ys         ys  0.95047164\n",
      "634      ys         ys  0.82569385\n",
      "635      ys         ys  0.89653075\n",
      "636      ys         ys   0.9999908\n",
      "637      ys         ys  0.80167824\n",
      "638      ys         jc   0.9414423\n",
      "639      ys         ys  0.99999774\n",
      "640      ys         ys    0.999998\n",
      "641      ys         ys   0.9999982\n",
      "642      ys         ys   0.9999976\n",
      "643      ys         ys   0.9999875\n",
      "644      ys         ys   0.9999982\n",
      "645      ys         ys   0.9999982\n",
      "646      ys         ys  0.99999857\n",
      "647      ys         ys   0.9999982\n",
      "648      ys         ys   0.9995695\n",
      "649      ys         ys   0.9999949\n",
      "650      ys         ys  0.99999213\n",
      "651      ys         ys   0.9999794\n",
      "652      ys         ys   0.9999783\n",
      "653      ys         ys  0.99998045\n",
      "654      ys         ys  0.99983406\n",
      "655      ys         ys   0.9999976\n",
      "656      ys         ys   0.9777634\n",
      "657      ys         ys   0.6579823\n",
      "658      ys         ys   0.9999939\n",
      "659      ys         ys  0.99999535\n",
      "660      ys         ys   0.9999949\n",
      "661      ys         ys   0.9694846\n",
      "662      ys         ys   0.9999852\n",
      "663      ys         ys   0.9999598\n",
      "664      ys         ys   0.9999094\n",
      "665      ys         ys  0.99751854\n",
      "666      ys         ys  0.99998796\n",
      "667      ys         ys  0.99999774\n",
      "668      ys         ys   0.9999857\n",
      "669      ys         ys  0.99987125\n",
      "670      ys         ys   0.9999981\n",
      "671      ys         ys   0.9999683\n",
      "672      ys         ys   0.9999968\n",
      "673      ys         ys  0.99999785\n",
      "674      ys         ys   0.9999969\n",
      "675      ys         ys    0.999959\n",
      "676      ys         ys    0.999995\n",
      "677      ys         ys  0.99999785\n",
      "678      ys         ys    0.999998\n",
      "679      ys         ys   0.9999988\n",
      "680      ys         ys    0.999998\n",
      "681      ys         ys  0.99999595\n",
      "682      ys         ys  0.99999833\n",
      "683      ys         ys  0.99999905\n",
      "684      ys         ys   0.8682067\n",
      "685      ys         ys   0.9999964\n",
      "686      ys         ys   0.9999969\n",
      "687      ys         ys   0.9999907\n",
      "688      ys         ys  0.99999607\n",
      "689      ys         ys  0.99944836\n",
      "690      ys         ys   0.9999943\n",
      "691      ys         ys   0.9999976\n",
      "692      ys         ys  0.99998796\n",
      "693      ys         ys  0.99999464\n",
      "694      ys         ys  0.99999666\n",
      "695      ys         ys   0.9999976\n",
      "696      ys         ys  0.99999785\n",
      "697      ys         ys  0.99999833\n",
      "698      ys         ys   0.9999732\n",
      "699      ys         ys  0.99999785\n",
      "700      ys         ys    0.999998\n",
      "701      ys         ys  0.99999857\n",
      "702      ys         ys   0.9999925\n",
      "703      ys         ys   0.9999958\n",
      "704      ys         ys    0.999998\n",
      "705      ys         ys  0.99999774\n",
      "706      ys         ys   0.9999981\n",
      "707      ys         ys  0.99999774\n",
      "708      ys         ys   0.9999974\n",
      "709      ys         ys   0.9999974\n",
      "710      ys         ys   0.9999987\n",
      "711      ys         ys    0.999982\n",
      "712      ys         ys  0.99999654\n",
      "713      ys         ys   0.9999734\n",
      "714      ys         ys  0.99998987\n",
      "715      ys         ys  0.99998033\n",
      "716      ys         ys   0.9999963\n",
      "717      ys         ys   0.9999896\n",
      "718      ys         ys   0.9999963\n",
      "719      ys         ys   0.9999981\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# # get prediction and its label # #\n",
    "####################################\n",
    "\n",
    "pred_proba = model.predict(pred_arr)\n",
    "\n",
    "# pred_proba = np.sum(pred_proba, axis=0)\n",
    "# pred_proba = np.reshape(pred_proba, (1, 9))\n",
    "\n",
    "pred = lb.inverse_transform(pred_proba)\n",
    "acc = np.max(pred_proba, axis=1)\n",
    "\n",
    "pred_results = np.column_stack((pred, acc))\n",
    "pred_results = np.column_stack((results, pred_results))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.DataFrame(data=pred_results, index=None, columns=['Results', 'Prediction', 'Accuracy'])\n",
    "# df = pd.DataFrame(data=pred_results, index=None, columns=['Prediction', 'Accuracy'])\n",
    "print(df)\n",
    "\n",
    "# =IF(EXACT(B2, C2), \"Match\", \"Nope\")\n",
    "\n",
    "df.to_csv(RESULT_NAME)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7d334f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d2798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8af20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3741765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
